# -*- coding: utf-8 -*-
"""imp_curricular_oferta.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11A6qf-GSfBSB3YbyS3cCRaxd0IePr9de

# Paquetes e importaciones y funciones
"""

import pandas as pd
import numpy as np
from datetime import datetime
from datetime import timedelta
from google.colab import sheets

# prompt: crear esta función # Tabla de frecuencias

def tabla_frecuencias(df, var, aux):
  """
  Esta función calcula y muestra una tabla de frecuencias y porcentajes para una variable dada en un DataFrame.

  Args:
    df: El DataFrame que contiene los datos.
    var: El nombre de la variable para la cual se calcularán las frecuencias.

  Returns:
    Un DataFrame con las frecuencias y porcentajes.
  """


  # Calcula las frecuencias
  frecuencias = df[var].value_counts(dropna=False)

  # Calcula los porcentajes
  total = frecuencias.sum()
  porcentajes = (frecuencias / total) * 100

  # sumar otra variable
  sum_aux = df.groupby(var)[aux].sum()
  # agregado variable
 # variable = df[var]

  # Crea un DataFrame con las frecuencias y porcentajes
  tabla = pd.DataFrame({
            # var:df[var], # agregado
      'Frecuencia': frecuencias,
      'Porcentaje': porcentajes,
            'aux': sum_aux

  })

  #return print(tabla)
  return tabla

# Función resumen por variable sumando el número de alumnos

def resum_var(bd, var1, var2):
  """
  Esta función calcula y muestra un resumen de la suma de una variable (var2) agrupada por otra variable (var1) en un DataFrame (bd).

  Args:
    bd: El DataFrame que contiene los datos.
    var1: El nombre de la variable para agrupar.
    var2: El nombre de la variable para sumar.

  Returns:
    Un DataFrame con el resumen.
  """
  tabla = bd.groupby(var1)[var2].sum().reset_index()
  total = tabla[var2].sum()
  tabla['Porcentaje'] = (tabla[var2] / total) * 100

  # Agrega una fila con el total
  tabla_total = pd.DataFrame({var1: ['Total'], var2: [total], 'Porcentaje': [100]})
  tabla = pd.concat([tabla, tabla_total], ignore_index=True)

  return print(tabla)

# Ejemplo de uso
#resum_var(dfmat, 'COD_DEPE', 'N_ALU')

# prompt: crear una función con # prompt: HISTOGRAMA dfmat2 'N_ALU' CON COLUMNAS MÁS ANGOSTAS MOSTRAR MEDIA Y MEDIANA Y DESVEST
# import matplotlib.pyplot as plt
# import seaborn as sns
# var= 'N_ALU'
# # Calcula la media, mediana y desviación estándar
# media = dfmat2[var].mean()
# mediana = dfmat2[var].median()
# desvest = dfmat2[var].std()
# # Crea el histograma
# plt.figure(figsize=(10, 6))  # Ajusta el tamaño de la

import matplotlib.pyplot as plt
import seaborn as sns

def histograma_resumen(df, var, bins_adj):
  """
  Esta función crea un histograma para una variable dada en un DataFrame,
  muestra la media, mediana y desviación estándar, y ajusta el ancho de las columnas.

  Args:
    df: El DataFrame que contiene los datos.
    var: El nombre de la variable para la cual se creará el histograma.
  """
  # Calcula la media, mediana y desviación estándar
  media = df[var].mean()
  mediana = df[var].median()
  desvest = df[var].std()

  # Crea el histograma
  plt.figure(figsize=(10, 6))
  sns.histplot(df[var], kde=False, bins=bins_adj)  # Ajusta el número de bins según sea necesario

  # Agrega líneas verticales para la media, mediana y desviación estándar
  plt.axvline(media, color='red', linestyle='dashed', linewidth=2, label=f'Media: {media:.2f}')
  #plt.axvline(mediana, color='green', linestyle='dashed', linewidth=2, label=f'Mediana: {mediana:.2f}')
  plt.axvline(desvest, color='None', linestyle='None', linewidth=2, label=f'Desv. Est.: {desvest:.2f}')

  plt.axvline(np.percentile(df[var], 25), color='orange', linestyle='dotted', linewidth=2, label=f'P25.: {np.percentile(df[var], 25):.2f}')
  plt.axvline(np.percentile(df[var], 50), color='green', linestyle='dotted', linewidth=2, label=f'P50.: {np.percentile(df[var], 50):.2f}')
  plt.axvline(np.percentile(df[var], 75), color='orange', linestyle='dotted', linewidth=2, label=f'P75.: {np.percentile(df[var], 75):.2f}')
  plt.axvline(np.percentile(df[var], 90), color='orange', linestyle='dotted', linewidth=2, label=f'P90.: {np.percentile(df[var], 90):.2f}')
  plt.axvline(np.percentile(df[var], 95), color='orange', linestyle='dotted', linewidth=2, label=f'P95.: {np.percentile(df[var], 95):.2f}')

  #plt.axvline(media + desvest, color='blue', linestyle='dotted', linewidth=2)
  #plt.axvline(media - desvest, color='blue', linestyle='dotted', linewidth=2)

  # Configura el título y etiquetas
  plt.title('Histograma de ' + var)
  plt.xlabel(var)
  plt.ylabel('Frecuencia')
  plt.legend()

  # Muestra el gráfico
  plt.show()

# Ejemplo de uso
# histograma_resumen(dfmat2, 'N_ALU')

import matplotlib.pyplot as plt
import seaborn as sns

def histograma_resumen_0(df, var, bins_adj):
  """
  Esta función crea un histograma para una variable dada en un DataFrame,
  muestra la media, mediana y desviación estándar, y ajusta el ancho de las columnas.

  Args:
    df: El DataFrame que contiene los datos.
    var: El nombre de la variable para la cual se creará el histograma.
  """
  df = df[df[var] != 0]  # Filtra los casos en que def_vig = 0

  # Calcula la media, mediana y desviación estándar
  media = df[var].mean()
  mediana = df[var].median()
  desvest = df[var].std()

  # Crea el histograma
  plt.figure(figsize=(10, 6))
  sns.histplot(df[var], kde=False, bins=bins_adj)  # Ajusta el número de bins según sea necesario

  # Agrega líneas verticales para la media, mediana y desviación estándar
  plt.axvline(media, color='red', linestyle='dashed', linewidth=2, label=f'Media: {media:.2f}')
  #plt.axvline(mediana, color='green', linestyle='dashed', linewidth=2, label=f'Mediana: {mediana:.2f}')
  plt.axvline(desvest, color='None', linestyle='None', linewidth=2, label=f'Desv. Est.: {desvest:.2f}')

  plt.axvline(np.percentile(df[var], 25), color='orange', linestyle='dotted', linewidth=2, label=f'P25.: {np.percentile(df[var], 25):.2f}')
  plt.axvline(np.percentile(df[var], 50), color='green', linestyle='dotted', linewidth=2, label=f'P50.: {np.percentile(df[var], 50):.2f}')
  plt.axvline(np.percentile(df[var], 75), color='orange', linestyle='dotted', linewidth=2, label=f'P75.: {np.percentile(df[var], 75):.2f}')
  plt.axvline(np.percentile(df[var], 90), color='orange', linestyle='dotted', linewidth=2, label=f'P90.: {np.percentile(df[var], 90):.2f}')
  plt.axvline(np.percentile(df[var], 95), color='orange', linestyle='dotted', linewidth=2, label=f'P95.: {np.percentile(df[var], 95):.2f}')

  #plt.axvline(media + desvest, color='blue', linestyle='dotted', linewidth=2)
  #plt.axvline(media - desvest, color='blue', linestyle='dotted', linewidth=2)

  # Configura el título y etiquetas
  plt.title('Histograma de ' + var)
  plt.xlabel(var)
  plt.ylabel('Frecuencia')
  plt.legend()

  # Muestra el gráfico
  plt.show()

# Ejemplo de uso
# histograma_resumen(dfmat2, 'N_ALU')

# prompt: crear una función con df2_agrupado = df2_1.groupby('SUBSECTOR1_lab')['caso'].sum().reset_index()
# df2_agrupado

def agrupa_cuenta(df, var, caso):
  """
  Esta función agrupa un DataFrame por una columna y suma los valores de otra columna.

  Args:
    df: El DataFrame a agrupar.
    columna_agrupacion: El nombre de la columna por la cual agrupar.
    columna_suma: El nombre de la columna cuyos valores se van a sumar.

  Returns:
    Un DataFrame con la suma de los valores agrupados.
  """
  df_agrupado = df.groupby(var)[caso].sum().reset_index()
  df_agrupado = df_agrupado.sort_values(by=caso, ascending=False)
  total = df_agrupado[caso].sum()
  df_agrupado['Porcentaje'] = (df_agrupado[caso] / total) * 100
  sheet = sheets.InteractiveSheet(df=df_agrupado)

  return sheet


  #return df_agrupado

# prompt: crear una función con df2_agrupado = df2_1.groupby('SUBSECTOR1_lab')['caso'].sum().reset_index()
# # df2_agrupado y ordenar por la variable caso de mayor a menor y agregar el porcentaje

def agrupa_cuenta_ordenada(df, var, caso):
  """
  Esta función agrupa un DataFrame por una columna y suma los valores de otra columna,
  ordenando los resultados de mayor a menor y agregando el porcentaje.

  Args:
    df: El DataFrame a agrupar.
    var: El nombre de la columna por la cual agrupar.
    caso: El nombre de la columna cuyos valores se van a sumar.

  Returns:
    Un DataFrame con la suma de los valores agrupados, ordenado y con porcentajes.
  """
  df_agrupado = df.groupby(var)[caso].sum().reset_index()
  df_agrupado = df_agrupado.sort_values(by=caso, ascending=False)
  total = df_agrupado[caso].sum()
  df_agrupado['Porcentaje'] = (df_agrupado[caso] / total) * 100
  return df_agrupado

# prompt: conectar con google drive

from google.colab import drive
drive.mount('/content/drive')

"""# Importar archivos"""

from google.colab import drive
drive.mount('/content/drive')

# dfdoc.csv es la base de cargos docentes con etiquetas

dir2='/content/drive/MyDrive/analisis_datos/imp_curricular/Insumos/dfdoc.csv'


df2 = pd.read_csv(dir2,
                 sep=';',
                 encoding='latin-1',
                 on_bad_lines='skip')

df2.info()

# prompt: en df2 mostrar tabla con los campos y el número de columna y el tipo de variable

# Crear una tabla con los campos, número de columna y tipo de variable
tabla_info = pd.DataFrame({
    'Campo': df2.columns,
    'Número de Columna': range(1, len(df2.columns) + 1),
    'Tipo de Variable': df2.dtypes
})

# Mostrar la tabla
tabla_info

# dfdoc21.csv es la base de cargos docentes con etiquetas y filtros

dir1='/content/drive/MyDrive/analisis_datos/imp_curricular/Insumos/dfdoc21.csv'

df = pd.read_csv(dir1,
                 sep=';',
                 encoding='latin-1',
                 on_bad_lines='skip')

df.info()

# Crear una tabla con los campos, número de columna y tipo de variable
tabla_info2 = pd.DataFrame({
    'Campo': df.columns,
    'Número de Columna': range(1, len(df.columns) + 1),
    'Tipo de Variable': df.dtypes
})

# Mostrar la tabla
tabla_info2

df.head()

"""# Procesamiento

Revisión base
"""

resum_var(df, 'ESTADO_ESTAB', 'caso')
resum_var(df, 'TIT_ID_1', 'caso')
resum_var(df, 'COD_ENS_1', 'caso')
resum_var(df, 'NIVEL1', 'caso')
resum_var(df, 'GRADO.1_1', 'caso')
resum_var(df, 'NIVEL1_lab', 'caso')
resum_var(df, 'nivel_sector_lab', 'caso')
#resum_var(df, 'ESP_ID_1', 'caso')

resum_var(df,'MEN_SIN_MENCION_1', 'caso')
resum_var(df, 'MEN_SIN_MENCION_2', 'caso')
resum_var(df, 'MEN_PLATICA_1', 'caso')
resum_var(df, 'MEN_PLATICA_2', 'caso')
resum_var(df, 'MEN_NATURALES_1', 'caso')
resum_var(df, 'MEN_NATURALES_2', 'caso')
resum_var(df, 'MEN_SOCIALES_1', 'caso')
resum_var(df, 'MEN_SOCIALES_2', 'caso')
resum_var(df, 'MEN_COMPUTACION_1', 'caso')
resum_var(df, 'MEN_COMPUTACION_2', 'caso')
resum_var(df, 'MEN_ED_FISICA_1', 'caso')
resum_var(df, 'MEN_ED_FISICA_2', 'caso')
resum_var(df, 'MEN_ED_MUSICA_1', 'caso')
resum_var(df, 'MEN_ED_MUSICA_2', 'caso')
resum_var(df, 'MEN_ED_TECNO_1', 'caso')
resum_var(df, 'MEN_ED_TECNO_2', 'caso')
resum_var(df, 'MEN_LENGUAJE_1', 'caso')
resum_var(df, 'MEN_LENGUAJE_2', 'caso')
resum_var(df, 'MEN_LENGUAJE_1', 'caso')
resum_var(df, 'MEN_MATE_2', 'caso')
resum_var(df, 'MEN_MATE_1', 'caso')
resum_var(df, 'MEN_RELIGION_2', 'caso')
resum_var(df, 'MEN_RELIGION_1', 'caso')
resum_var(df, 'MEN_TRASTORNOS_2', 'caso')
resum_var(df, 'MEN_TRASTORNOS_1', 'caso')
resum_var(df, 'MEN_INGLES_2', 'caso')
resum_var(df, 'MEN_INGLES_1', 'caso')
resum_var(df, 'MEN_FRANCES_2', 'caso')
resum_var(df, 'MEN_ALEMAN_1', 'caso')
resum_var(df, 'MEN_ALEMAN_2', 'caso')
resum_var(df, 'MEN_OTRO_IDIOMA_1', 'caso')
resum_var(df, 'MEN_OTRO_IDIOMA_2', 'caso')
resum_var(df, 'MEN_INTERCULTURAL_1', 'caso')
resum_var(df, 'MEN_INTERCULTURAL_2', 'caso')
resum_var(df, 'MEN_ADMINISTRACION_1', 'caso')
resum_var(df, 'MEN_ADMINISTRACION_2', 'caso')
resum_var(df, 'MEN_CURRICULUM_1', 'caso')
resum_var(df, 'MEN_CURRICULUM_2', 'caso')
resum_var(df, 'MEN_ED_PARV_1', 'caso')
resum_var(df, 'MEN_ED_PARV_2', 'caso')
resum_var(df, 'MEN_ED_AD_1', 'caso')
resum_var(df, 'MEN_ED_AD_2', 'caso')
resum_var(df, 'MEN_DES_COM_1', 'caso')
resum_var(df, 'MEN_DES_COM_2', 'caso')
resum_var(df, 'MEN_DIS_INT_1', 'caso')
resum_var(df, 'MEN_DIS_INT_2', 'caso')
resum_var(df, 'MEN_ORIENTACION_1', 'caso')
resum_var(df, 'MEN_ORIENTACION_2', 'caso')

"""dup_rbd"""

# duplicados
df  =df .assign(dup_rbd=df [['RBD']].duplicated())
df ['dup_rbd'].value_counts(dropna=False)

# prompt: df mostrar los campos  MRUN GRADO.1_1 GRADO.2_1  GRADO.3_1 GRADO.4_1  GRADO.5_1  GRADO.6_1  GRADO.7_1

campos_a_mostrar = ['MRUN', 'COD_ENS_1','GRADO.1_1', 'GRADO.2_1', 'GRADO.3_1', 'GRADO.4_1', 'GRADO.5_1', 'GRADO.6_1', 'GRADO.7_1']
#campos_a_mostrar = ['COD_ENS_1', 'COD_ENS_2']

df_mostrar = df[campos_a_mostrar]
df_mostrar

# prompt: calcula la frecuencia agrupada de ['COD_ENS_1', 'COD_ENS_2']  y el porcentaje ordena de mayor a menor frecuencia, poner una columna con la suma de los porcentajes

# Calcula la frecuencia agrupada de 'COD_ENS_1' y 'COD_ENS_2' y el porcentaje, ordenado de mayor a menor frecuencia
frecuencia_cod_ens = df.groupby(['COD_ENS_1', 'COD_ENS_2'])['caso'].count().reset_index()
frecuencia_cod_ens = frecuencia_cod_ens.rename(columns={'caso': 'Frecuencia'})
total_casos = frecuencia_cod_ens['Frecuencia'].sum()
frecuencia_cod_ens['Porcentaje'] = (frecuencia_cod_ens['Frecuencia'] / total_casos) * 100
frecuencia_cod_ens = frecuencia_cod_ens.sort_values(by='Frecuencia', ascending=False)

# Calcula la suma acumulada de los porcentajes
frecuencia_cod_ens['Suma_Porcentaje'] = frecuencia_cod_ens['Porcentaje'].cumsum()

# Muestra la tabla resultante
frecuencia_cod_ens

# prompt: crear la variable ens_grado =  COD_ENS_1&"_"& GRADO.1_1&"-"& GRADO.2_1&"-"&   GRADO.3_1 &"-"&  GRADO.4_1 &"-"&   GRADO.5_1 &"-"&  GRADO.6_1 &"-"&  GRADO.7_1

# Crear la variable ens_grado concatenando las columnas especificadas
df['ens_grado'] = df['GRADO.1_1'].astype(str) + '-' + \
                  df['GRADO.2_1'].astype(str) + '-' + \
                  df['GRADO.3_1'].astype(str) + '-' + \
                  df['GRADO.4_1'].astype(str) + '-' + \
                  df['GRADO.5_1'].astype(str) + '-' + \
                  df['GRADO.6_1'].astype(str) + '-' + \
                  df['GRADO.7_1'].astype(str)

#df['COD_ENS_1'].astype(str) + '_' + \
# Mostrar la nueva variable
print(df['ens_grado'])

# prompt: mostrar casos en que 'COD_ENS_1' =110 y 'COD_ENS_2=310, MRUN, ens_grado  'COD_ENS_1' y 'COD_ENS_2'

# Filter the DataFrame for the specified conditions
filtered_df = df[(df['COD_ENS_1'] == 110) & (df['COD_ENS_2'] == 310)]

# Select the desired columns
result_df = filtered_df[['MRUN', 'COD_ENS_1', 'COD_ENS_2', 'ens_grado']] # Assuming 'ens_grado' exists in your DataFrame

# Display the result
result_df

# prompt: convertir estas variable a número 'MEN_SIN_MENCION_1'

variables_a_convertir = [
    'MEN_SIN_MENCION_1', 'MEN_SIN_MENCION_2',
    'MEN_PLATICA_1', 'MEN_PLATICA_2',
    'MEN_NATURALES_1', 'MEN_NATURALES_2',
    'MEN_SOCIALES_1', 'MEN_SOCIALES_2',
    'MEN_COMPUTACION_1', 'MEN_COMPUTACION_2',
    'MEN_ED_FISICA_1','MEN_ED_FISICA_2',
    'MEN_ED_MUSICA_1', 'MEN_ED_MUSICA_2',
    'MEN_ED_TECNO_1', 'MEN_ED_TECNO_2',
    'MEN_LENGUAJE_1', 'MEN_LENGUAJE_2',
    'MEN_MATE_2', 'MEN_MATE_1',
    'MEN_RELIGION_2', 'MEN_RELIGION_1',
    'MEN_TRASTORNOS_2', 'MEN_TRASTORNOS_1',
    'MEN_INGLES_1', 'MEN_INGLES_2',
    'MEN_FRANCES_1', 'MEN_FRANCES_2',
    'MEN_ALEMAN_1', 'MEN_ALEMAN_2',
    'MEN_OTRO_IDIOMA_1', 'MEN_OTRO_IDIOMA_2',
    'MEN_INTERCULTURAL_1', 'MEN_INTERCULTURAL_2',
    'MEN_ADMINISTRACION_1','MEN_ADMINISTRACION_2',
    'MEN_CURRICULUM_1', 'MEN_CURRICULUM_2',
    'MEN_ED_PARV_1', 'MEN_ED_PARV_2',
    'MEN_ED_AD_1', 'MEN_ED_AD_2',
    'MEN_DES_COM_1', 'MEN_DES_COM_2',
    'MEN_DIS_INT_1', 'MEN_DIS_INT_2',
    'MEN_ORIENTACION_1', 'MEN_ORIENTACION_2',
    'MEN_INT_ESC_1', 'MEN_INT_ESC_2',
    'MEN_PSICO_1', 'MEN_PSICO_2'
                                        ]


for variable in variables_a_convertir:
  df[variable] = pd.to_numeric(df[variable], errors='coerce')

# prompt: reemplazar perdidos por 0 en 'MEN_SIN_MENCION_1','MEN_SIN_MENCION_2','MEN_PLATICA_1','MEN_PLATICA_2','MEN_NATURALES_1','MEN_NATURALES_2','MEN_SOCIALES_1','MEN_SOCIALES_2','MEN_COMPUTACION_1','MEN_COMPUTACION_2','MEN_ED_FISICA_1','MEN_ED_FISICA_2','MEN_ED_MUSICA_1','MEN_ED_MUSICA_2','MEN_ED_TECNO_1','MEN_ED_TECNO_2','MEN_LENGUAJE_1','MEN_LENGUAJE_2','MEN_LENGUAJE_1','MEN_MATE_2','MEN_MATE_1','MEN_R

variables_a_reemplazar = variables_a_convertir


for variable in variables_a_reemplazar:
  df[variable] = df[variable].fillna(0)

# prompt:  prompt: en df crea la variable cons_men =0, luego reemplazala  por la siguiente suma de
#   'MEN_PLATICA_1'+'MEN_PLATICA_2'+'MEN_NATURALES_1'+
#    'MEN_NATURALES_2'+'MEN_SOCIALES_1'+'MEN_SOCIALES_2'+'MEN_COMPUTACION_1'+'MEN_COMPUTACION_2'+'MEN_ED_FISICA_1'+
#       'MEN_ED_FISICA_2'+'MEN_ED_MUSICA_1'+'MEN_ED_MUSICA_2'+'MEN_ED_TECNO_1'+'MEN_ED_TECNO_2'+'MEN_LENGUAJE_1'+
#    'MEN_LENGUAJE_2'+'MEN_MATE_1'

df['cons_men'] = 0  # Crea la variable cons_men con valor 0

# Reemplaza cons_men con la suma de las variables especificadas
df['cons_men'] =  df['MEN_PLATICA_1']+ df['MEN_PLATICA_2']+\
                  df['MEN_NATURALES_1']+ df['MEN_NATURALES_2']+\
                  df['MEN_SOCIALES_1'] + df['MEN_SOCIALES_2'] + \
                  df['MEN_COMPUTACION_1'] + df['MEN_COMPUTACION_2'] + \
                  df['MEN_ED_FISICA_1'] + df['MEN_ED_FISICA_2'] + \
                  df['MEN_ED_MUSICA_1'] + df['MEN_ED_MUSICA_2'] + \
                  df['MEN_ED_TECNO_1'] + df['MEN_ED_TECNO_2'] + \
                  df['MEN_LENGUAJE_1'] +  df['MEN_LENGUAJE_2'] +\
                  df['MEN_MATE_1'] + df['MEN_MATE_2']+\
                  df['MEN_RELIGION_2'] +  df['MEN_RELIGION_1'] + \
                  df['MEN_TRASTORNOS_1'] +  df['MEN_TRASTORNOS_2']+\
                  df['MEN_INGLES_1'] +  df['MEN_INGLES_2'] + \
                  df['MEN_FRANCES_1'] +  df['MEN_FRANCES_2'] + \
                  df['MEN_ALEMAN_1'] +  df['MEN_ALEMAN_2'] + \
                  df['MEN_OTRO_IDIOMA_1'] +  df['MEN_OTRO_IDIOMA_2'] + \
                  df['MEN_INTERCULTURAL_1'] +  df['MEN_INTERCULTURAL_2'] + \
                  df['MEN_ADMINISTRACION_1'] +  df['MEN_ADMINISTRACION_2'] + \
                  df['MEN_CURRICULUM_1'] +  df['MEN_CURRICULUM_2'] + \
                  df['MEN_ED_PARV_1'] +  df['MEN_ED_PARV_2']  + \
                  df['MEN_ED_AD_1'] +  df['MEN_ED_AD_2']  + \
                  df['MEN_DES_COM_1'] +  df['MEN_DES_COM_2']  + \
                  df['MEN_DIS_INT_1'] +  df['MEN_DIS_INT_2']  + \
                  df['MEN_ORIENTACION_1'] +  df['MEN_ORIENTACION_2']  + \
                  df['MEN_INT_ESC_1'] +  df['MEN_INT_ESC_2']  + \
                  df['MEN_PSICO_1'] +  df['MEN_PSICO_2']

# prompt: frecuencia df['cons_men']

tabla_frecuencias(df, 'cons_men', 'caso')

# prompt: agrupa por ens_grado y suma la variable caso

var= variables_a_convertir


df_men=agrupa_cuenta_ordenada(df, var, 'caso')
df_men =df_men.sort_values(by=['caso'], ascending=False)




# exporta a csv y luego importa

df_men.to_csv("/content/drive/MyDrive/analisis_datos/imp_curricular/Insumos/df_men.csv",
               sep=";",
               encoding='iso-8859-1')

dir3='/content/drive/MyDrive/analisis_datos/imp_curricular/Insumos/df_men.csv'

df_men = pd.read_csv(dir3,
                 sep=';',
                 encoding='latin-1',
                 on_bad_lines='skip')


# exportar drive google

#### EXPORTA RBD ####

dfrev=df_men

from google.colab import auth
auth.authenticate_user()

import gspread
from google.auth import default
creds, _ = default()

gc = gspread.authorize(creds)

from gspread_dataframe import set_with_dataframe
sheet = gc.open_by_key("1pOUtbMJBXn6poNcxbBRCAYdQw2KYkVSIcAcwef_SaBY").sheet1
set_with_dataframe(sheet, dfrev)

var=[ 'COD_ENS_1', 'COD_ENS_lab', 'ens_grado']
agrupa_cuenta_ordenada(df, var, 'caso')

# prompt: frecuencia clas_ens_grado

#tabla_frecuencias(df, 'clas_ens_grado', 'caso')

"""# Clasificación de horas

horas_pl2
"""

# genera horas_pl2

import math

df['horas_pl2'] = df['HORAS_AULA']*60/45*0.65
df['horas_pl2'] = df['horas_pl2'].apply(math.floor) # redondea al número inferior
df['horas_pl2'].describe()

# prompt: genera un histograma con horas_pl2

# Generar el histograma para horas_pl2
histograma_resumen(df, 'horas_pl2', 50)  # Ajusta el número de bins según sea necesario

"""# Aplica clasificación"""

df['clasif'] ="NA"

# prompt: renombrar clasif por Asig

df = df.rename(columns={'Asig': 'Asig_ref'})

# para ocupar el mismo código de t11
t11=df

# prompt: frecuencia 'clasif'

tabla_frecuencias(t11, 'clasif', 'caso')

# prompt: si SECTOR1_lab = Lenguaje y Comunicación entonces clasif = "LyL"


# LyL


t11.loc[(t11['SUBSECTOR1_lab'] == 'Lenguaje y Comunicación') &
          (t11['clasif'] == 'NA'), 'clasif'] = 'LyL'

t11.loc[(t11['SECTOR1_lab'] == 'Lenguaje y Comunicación')&
        (t11['SUBSECTOR1_lab'] == 'Otro')&
         #(t11['ESP_ID_1_lab'] == 'Lenguaje y Comunicación')&
          #(t11['MEN_LENGUAJE_1'] == '1')&
            (t11['clasif'] == 'NA'), 'clasif'] = 'LyL'

t11.loc[(t11['SECTOR1_lab'] == 'Lenguaje y Comunicación')&
        (t11['SUBSECTOR1_lab'] == 'Lenguaje y Comunicación')&
         (t11['ESP_ID_1_lab'] == 'Lenguaje y Comunicación')&
          #(t11['MEN_LENGUAJE_1'] == '1')&
            (t11['clasif'] == 'NA'), 'clasif'] = 'LyL'


t11.loc[(t11['SECTOR1_lab'] == 'General')&
        (t11['SUBSECTOR1_lab'] == 'General')&
         (t11['ESP_ID_1_lab'] == 'Lenguaje y Comunicación')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'LyL'

t11.loc[(t11['SECTOR1_lab'] == 'General')&
        (t11['SUBSECTOR1_lab'] == 'General')&
         (t11['ESP_ID_1_lab'] == 'Castellano')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'LyL'

t11.loc[(t11['SECTOR1_lab'] == 'General')&
        (t11['SUBSECTOR1_lab'] == 'General')&
         #(t11['ESP_ID_1_lab'] == 'Sin especialidad')&
          (t11['cons_men'] == 1)&
            (t11['MEN_LENGUAJE_1'] == 1), 'clasif'] = 'LyL'

t11.loc[(t11['SECTOR1_lab'] == 'General')&
        (t11['SUBSECTOR1_lab'] == 'General')&
         #(t11['ESP_ID_1_lab'] == 'Sin especialidad')&
          (t11['cons_men'] == 1)&
            (t11['MEN_LENGUAJE_2'] == 1), 'clasif'] = 'LyL'

t11.loc[(t11['SECTOR1_lab'] == 'Otros')&
        (t11['SUBSECTOR1_lab'] == 'Otro Formación General')&
         #(t11['ESP_ID_1_lab'] == 'Sin especialidad')&
          (t11['cons_men'] == 1)&
            (t11['MEN_LENGUAJE_1'] == 1), 'clasif'] = 'LyL'

t11.loc[(t11['SECTOR1_lab'] == 'Otros')&
        (t11['SUBSECTOR1_lab'] == 'Otro Formación General')&
         #(t11['ESP_ID_1_lab'] == 'Sin especialidad')&
          (t11['cons_men'] == 1)&
            (t11['MEN_LENGUAJE_2'] == 1), 'clasif'] = 'LyL'


t11.loc[(t11['SECTOR1_lab'] == 'Otros')&
        (t11['SUBSECTOR1_lab'] == 'Otro Formación General')&
         (t11['ESP_ID_1_lab'] == 'Castellano')#&
         # (t11['cons_men'] == 1)&
           # (t11['MEN_LENGUAJE_1'] == 1)
            , 'clasif'] = 'LyL'


# Ing
t11.loc[(t11['SUBSECTOR1_lab'] == 'Idioma Extranjero Inglés') &
          (t11['clasif'] == 'NA'), 'clasif'] = 'Ing'


t11.loc[(t11['SECTOR1_lab'] == 'General')&
        (t11['SUBSECTOR1_lab'] == 'General')&
         (t11['ESP_ID_1_lab'] == 'Inglés')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'Ing'

t11.loc[(t11['SECTOR1_lab'] == 'Otros')&
        (t11['SUBSECTOR1_lab'] == 'Otro Formación General')&
         (t11['ESP_ID_1_lab'] == 'Inglés')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'Ing'

t11.loc[(t11['SECTOR1_lab'] == 'Lenguaje y Comunicación')&
        (t11['SUBSECTOR1_lab'] == 'Idioma Extranjero (otro)')&
        #(t11['ESP_ID_1_lab'] == 'Inglés')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'Ing'

t11.loc[(t11['SECTOR1_lab'] == 'General')&
        (t11['SUBSECTOR1_lab'] == 'General')&
         #(t11['ESP_ID_1_lab'] == 'Sin especialidad')&
          (t11['cons_men'] == 1)&
            (t11['MEN_INGLES_1'] == 1), 'clasif'] = 'Ing'

t11.loc[(t11['SECTOR1_lab'] == 'Otros')&
        (t11['SUBSECTOR1_lab'] == 'Otro Formación General')&
         #(t11['ESP_ID_1_lab'] == 'Sin especialidad')&
          (t11['cons_men'] == 1)&
            (t11['MEN_INGLES_1'] == 1), 'clasif'] = 'Ing'

t11.loc[(t11['SECTOR1_lab'] == 'General')&
        (t11['SUBSECTOR1_lab'] == 'General')&
         #(t11['ESP_ID_1_lab'] == 'Sin especialidad')&
          (t11['cons_men'] == 1)&
            (t11['MEN_INGLES_2'] == 1), 'clasif'] = 'Ing'

t11.loc[(t11['SECTOR1_lab'] == 'Otros')&
        (t11['SUBSECTOR1_lab'] == 'Otro Formación General')&
         #(t11['ESP_ID_1_lab'] == 'Sin especialidad')&
          (t11['cons_men'] == 1)&
            (t11['MEN_INGLES_2'] == 1), 'clasif'] = 'Ing'


#Relig
t11.loc[(t11['SUBSECTOR1_lab'] == 'Religión') & (t11['clasif'] == 'NA'), 'clasif'] = 'Relig'

t11.loc[(t11['SECTOR1_lab'] == 'General')&
        (t11['SUBSECTOR1_lab'] == 'General')&
         (t11['ESP_ID_1_lab'] == 'Religión')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'Relig'

t11.loc[(t11['SECTOR1_lab'] == 'General')&
        (t11['SUBSECTOR1_lab'] == 'General')&
         #(t11['ESP_ID_1_lab'] == 'Sin especialidad')&
          (t11['cons_men'] == 1)&
            (t11['MEN_RELIGION_1'] == 1), 'clasif'] = 'Relig'

t11.loc[(t11['SECTOR1_lab'] == 'Otros')&
        (t11['SUBSECTOR1_lab'] == 'Otro Formación General')&
         #(t11['ESP_ID_1_lab'] == 'Sin especialidad')&
          (t11['cons_men'] == 1)&
            (t11['MEN_RELIGION_1'] == 1), 'clasif'] = 'Relig'

t11.loc[(t11['SECTOR1_lab'] == 'General')&
        (t11['SUBSECTOR1_lab'] == 'General')&
         #(t11['ESP_ID_1_lab'] == 'Sin especialidad')&
          (t11['cons_men'] == 1)&
            (t11['MEN_RELIGION_2'] == 1), 'clasif'] = 'Relig'

t11.loc[(t11['SECTOR1_lab'] == 'Otros')&
        (t11['SUBSECTOR1_lab'] == 'Otro Formación General')&
         #(t11['ESP_ID_1_lab'] == 'Sin especialidad')&
          (t11['cons_men'] == 1)&
            (t11['MEN_RELIGION_2'] == 1), 'clasif'] = 'Relig'

#Tec
t11.loc[(t11['SECTOR1_lab'] == 'Tecnología') & (t11['clasif'] == 'NA'), 'clasif'] = 'Tec'
t11.loc[(t11['SECTOR1_lab'] == 'Educación Tecnológica') & (t11['clasif'] == 'NA'), 'clasif'] = 'Tec'


t11.loc[(t11['SECTOR1_lab'] == 'General')&
        (t11['SUBSECTOR1_lab'] == 'General')&
         #(t11['ESP_ID_1_lab'] == 'Sin especialidad')&
          (t11['cons_men'] == 1)&
            (t11['MEN_ED_TECNO_1'] == 1), 'clasif'] = 'Tec'


t11.loc[(t11['SECTOR1_lab'] == 'Otros')&
        (t11['SUBSECTOR1_lab'] == 'Otro Formación General')&
         #(t11['ESP_ID_1_lab'] == 'Sin especialidad')&
          (t11['cons_men'] == 1)&
            (t11['MEN_ED_TECNO_1'] == 1), 'clasif'] = 'Tec'


t11.loc[(t11['SECTOR1_lab'] == 'General')&
        (t11['SUBSECTOR1_lab'] == 'General')&
         #(t11['ESP_ID_1_lab'] == 'Sin especialidad')&
          (t11['cons_men'] == 1)&
            (t11['MEN_ED_TECNO_2'] == 1), 'clasif'] = 'Tec'

t11.loc[(t11['SECTOR1_lab'] == 'Otros')&
        (t11['SUBSECTOR1_lab'] == 'Otro Formación General')&
         #(t11['ESP_ID_1_lab'] == 'Sin especialidad')&
          (t11['cons_men'] == 1)&
            (t11['MEN_ED_TECNO_2'] == 1), 'clasif'] = 'Tec'

#Ed_Fis
t11.loc[(t11['SECTOR1_lab'] == 'Educación Física') & (t11['clasif'] == 'NA'), 'clasif'] = 'Ed_Fis'

t11.loc[(t11['SECTOR1_lab'] == 'General')&
        (t11['SUBSECTOR1_lab'] == 'General')&
         (t11['ESP_ID_1_lab'] == 'Educación Física')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'Ed_Fis'

t11.loc[(t11['SECTOR1_lab'] == 'Otros')&
        (t11['SUBSECTOR1_lab'] == 'Otro Formación General')&
         (t11['ESP_ID_1_lab'] == 'Educación Física')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'Ed_Fis'

t11.loc[(t11['SECTOR1_lab'] == 'General')&
        (t11['SUBSECTOR1_lab'] == 'General')&
         #(t11['ESP_ID_1_lab'] == 'Sin especialidad')&
          (t11['cons_men'] == 1)&
            (t11['MEN_ED_FISICA_1'] == 1), 'clasif'] = 'Ed_Fis'

t11.loc[(t11['SECTOR1_lab'] == 'Otros')&
        (t11['SUBSECTOR1_lab'] == 'Otro Formación General')&
         #(t11['ESP_ID_1_lab'] == 'Sin especialidad')&
          (t11['cons_men'] == 1)&
            (t11['MEN_ED_FISICA_1'] == 1), 'clasif'] = 'Ed_Fis'


t11.loc[(t11['SECTOR1_lab'] == 'General')&
        (t11['SUBSECTOR1_lab'] == 'General')&
         #(t11['ESP_ID_1_lab'] == 'Sin especialidad')&
          (t11['cons_men'] == 1)&
            (t11['MEN_ED_FISICA_2'] == 1), 'clasif'] = 'Ed_Fis'

t11.loc[(t11['SECTOR1_lab'] == 'Otros')&
        (t11['SUBSECTOR1_lab'] == 'Otro Formación General')&
         #(t11['ESP_ID_1_lab'] == 'Sin especialidad')&
          (t11['cons_men'] == 1)&
            (t11['MEN_ED_FISICA_2'] == 1), 'clasif'] = 'Ed_Fis'


#Mat
t11.loc[(t11['SECTOR1_lab'] == 'Matemática') & (t11['clasif'] == 'NA'), 'clasif'] = 'Mat'

t11.loc[(t11['SECTOR1_lab'] == 'General')&
        (t11['SUBSECTOR1_lab'] == 'General')&
         (t11['ESP_ID_1_lab'] == 'Matemática')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'Mat'

t11.loc[(t11['SECTOR1_lab'] == 'Otros')&
        (t11['SUBSECTOR1_lab'] == 'Otro Formación General')&
         (t11['ESP_ID_1_lab'] == 'Matemática')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'Mat'


t11.loc[(t11['SECTOR1_lab'] == 'General')&
        (t11['SUBSECTOR1_lab'] == 'General')&
         #(t11['ESP_ID_1_lab'] == 'Sin especialidad')&
          (t11['cons_men'] == 1)&
            (t11['MEN_MATE_1'] == 1), 'clasif'] = 'Mat'


t11.loc[(t11['SECTOR1_lab'] == 'General')&
        (t11['SUBSECTOR1_lab'] == 'General')&
         #(t11['ESP_ID_1_lab'] == 'Sin especialidad')&
          (t11['cons_men'] == 1)&
            (t11['MEN_MATE_2'] == 1), 'clasif'] = 'Mat'


t11.loc[(t11['SECTOR1_lab'] == 'Otros')&
        (t11['SUBSECTOR1_lab'] == 'Otro Formación General')&
         #(t11['ESP_ID_1_lab'] == 'Sin especialidad')&
          (t11['cons_men'] == 1)&
            (t11['MEN_MATE_1'] == 1), 'clasif'] = 'Mat'

t11.loc[(t11['SECTOR1_lab'] == 'Otros')&
        (t11['SUBSECTOR1_lab'] == 'Otro Formación General')&
         #(t11['ESP_ID_1_lab'] == 'Sin especialidad')&
          (t11['cons_men'] == 1)&
            (t11['MEN_MATE_2'] == 1), 'clasif'] = 'Mat'

#CN
t11.loc[(t11['SECTOR1_lab'] == 'Ciencias Naturales') & (t11['clasif'] == 'NA'), 'clasif'] = 'CN'
t11.loc[(t11['SECTOR1_lab'] == 'Ciencia')&(t11['SUBSECTOR1_lab'] == 'Estudio y Comprensión de la Naturaleza') & (t11['clasif'] == 'NA'), 'clasif'] = 'CN'


t11.loc[(t11['SECTOR1_lab'] == 'General')&
        (t11['SUBSECTOR1_lab'] == 'General')&
         (t11['ESP_ID_1_lab'] == 'Ciencias Naturales')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'CN'

t11.loc[(t11['SECTOR1_lab'] == 'Ciencia')&
        (t11['SUBSECTOR1_lab'] == 'Otro')&
         #(t11['ESP_ID_1_lab'] == 'Ciencias Naturales')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'CN'


t11.loc[(t11['SECTOR1_lab'] == 'General')&
        (t11['SUBSECTOR1_lab'] == 'General')&
         #(t11['ESP_ID_1_lab'] == 'Sin especialidad')&
          (t11['cons_men'] == 1)&
            (t11['MEN_NATURALES_1'] == 1), 'clasif'] = 'CN'

t11.loc[(t11['SECTOR1_lab'] == 'Otros')&
        (t11['SUBSECTOR1_lab'] == 'Otro Formación General')&
         #(t11['ESP_ID_1_lab'] == 'Sin especialidad')&
          (t11['cons_men'] == 1)&
            (t11['MEN_NATURALES_1'] == 1), 'clasif'] = 'CN'

t11.loc[(t11['SECTOR1_lab'] == 'General')&
        (t11['SUBSECTOR1_lab'] == 'General')&
         #(t11['ESP_ID_1_lab'] == 'Sin especialidad')&
          (t11['cons_men'] == 1)&
            (t11['MEN_NATURALES_2'] == 1), 'clasif'] = 'CN'


t11.loc[(t11['SECTOR1_lab'] == 'Otros')&
        (t11['SUBSECTOR1_lab'] == 'Otro Formación General')&
         #(t11['ESP_ID_1_lab'] == 'Sin especialidad')&
          (t11['cons_men'] == 1)&
            (t11['MEN_NATURALES_2'] == 1), 'clasif'] = 'CN'


t11.loc[(t11['SECTOR1_lab'] == 'Otros')&
        (t11['SUBSECTOR1_lab'] == 'Otro Formación General')&
         (t11['ESP_ID_1_lab'] == 'Física')#&
         # (t11['cons_men'] == 1)&
           # (t11['MEN_LENGUAJE_1'] == 1)
            , 'clasif'] = 'CN'

t11.loc[(t11['SECTOR1_lab'] == 'Otros')&
        (t11['SUBSECTOR1_lab'] == 'Otro Formación General')&
         (t11['ESP_ID_1_lab'] == 'Química')#&
         # (t11['cons_men'] == 1)&
           # (t11['MEN_LENGUAJE_1'] == 1)
            , 'clasif'] = 'CN'

t11.loc[(t11['SECTOR1_lab'] == 'Otros')&
        (t11['SUBSECTOR1_lab'] == 'Otro Formación General')&
         (t11['ESP_ID_1_lab'] == 'Biología')#&
         # (t11['cons_men'] == 1)&
           # (t11['MEN_LENGUAJE_1'] == 1)
            , 'clasif'] = 'CN'

#Ori
t11.loc[(t11['SECTOR1_lab'] == 'Orientación') & (t11['clasif'] == 'NA'), 'clasif'] = 'Ori'

#t11.loc[(t11['SECTOR1_lab'] == 'General')&
#        (t11['SUBSECTOR1_lab'] == 'General')&
#         #(t11['ESP_ID_1_lab'] == 'Sin especialidad')&
#          (t11['cons_men'] == 1)&
#            (t11['MEN_ORIENTACION_1'] == 1), 'clasif'] = 'Ori'

#t11.loc[(t11['SECTOR1_lab'] == 'Otros')&
#        (t11['SUBSECTOR1_lab'] == 'Otro Formación General')&
#         #(t11['ESP_ID_1_lab'] == 'Sin especialidad')&
#          (t11['cons_men'] == 1)&
#            (t11['MEN_ORIENTACION_1'] == 1), 'clasif'] = 'Ori'

#t11.loc[(t11['SECTOR1_lab'] == 'General')&
#        (t11['SUBSECTOR1_lab'] == 'General')&
#         #(t11['ESP_ID_1_lab'] == 'Sin especialidad')&
#          (t11['cons_men'] == 1)&
#            (t11['MEN_ORIENTACION_2'] == 1), 'clasif'] = 'Ori'

#t11.loc[(t11['SECTOR1_lab'] == 'Otros')&
#        (t11['SUBSECTOR1_lab'] == 'Otro Formación General')&
#         #(t11['ESP_ID_1_lab'] == 'Sin especialidad')&
#          (t11['cons_men'] == 1)&
#            (t11['MEN_ORIENTACION_2'] == 1), 'clasif'] = 'Ori'



#Art_vis
t11.loc[(t11['SUBSECTOR1_lab'] == 'Artes Visuales') & (t11['clasif'] == 'NA'), 'clasif'] = 'Art_Vis'

t11.loc[(t11['SECTOR1_lab'] == 'General')&
        (t11['SUBSECTOR1_lab'] == 'General')&
         (t11['ESP_ID_1_lab'] == 'Artes Plásticas')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'Art_Vis'

t11.loc[(t11['SECTOR1_lab'] == 'Artes')&
        (t11['SUBSECTOR1_lab'] == 'Educación Artística')&
         (t11['ESP_ID_1_lab'] == 'Artes Plásticas')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'Art_Vis'

t11.loc[(t11['SECTOR1_lab'] == 'Artes')&
        (t11['SUBSECTOR1_lab'] == 'Otro')&
         (t11['ESP_ID_1_lab'] == 'Artes Plásticas')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'Art_Vis'


t11.loc[(t11['SECTOR1_lab'] == 'Artes')&
        (t11['SUBSECTOR1_lab'] == 'Educación Artística')&
         (t11['ESP_ID_1_lab'] == 'Artes Visuales')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'Art_Vis'

t11.loc[(t11['SECTOR1_lab'] == 'Artes')&
        (t11['SUBSECTOR1_lab'] == 'Educación Artística')&
         (t11['ESP_ID_1_lab'] == 'Sin especialidad')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'Art_Vis'

t11.loc[(t11['SECTOR1_lab'] == 'Artes')&
        (t11['SUBSECTOR1_lab'] == 'Educación Artística')&
         (t11['ESP_ID_1_lab'] == 'Otra especialidad')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'Art_Vis'


t11.loc[(t11['SECTOR1_lab'] == 'Artes')&
        (t11['SUBSECTOR1_lab'] == 'Otro')&
         #(t11['ESP_ID_1_lab'] == 'Otra especialidad')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'Art_Vis'

t11.loc[(t11['SECTOR1_lab'] == 'Educación Artística')&
        (t11['SUBSECTOR1_lab'] == 'Otro')&
         #(t11['ESP_ID_1_lab'] == 'Otra especialidad')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'Art_Vis'


t11.loc[(t11['SECTOR1_lab'] == 'Artes')&
        (t11['SUBSECTOR1_lab'] == 'Educación Artística')&
         #(t11['ESP_ID_1_lab'] == 'Otra especialidad')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'Art_Vis'


t11.loc[(t11['SECTOR1_lab'] == 'General')&
        (t11['SUBSECTOR1_lab'] == 'General')&
         #(t11['ESP_ID_1_lab'] == 'Sin especialidad')&
          (t11['cons_men'] == 1)&
            (t11['MEN_PLATICA_1'] == 1), 'clasif'] = 'Art_Vis'

t11.loc[(t11['SECTOR1_lab'] == 'Otros')&
        (t11['SUBSECTOR1_lab'] == 'Otro Formación General')&
         #(t11['ESP_ID_1_lab'] == 'Sin especialidad')&
          (t11['cons_men'] == 1)&
            (t11['MEN_PLATICA_1'] == 1), 'clasif'] = 'Art_Vis'

t11.loc[(t11['SECTOR1_lab'] == 'General')&
        (t11['SUBSECTOR1_lab'] == 'General')&
         #(t11['ESP_ID_1_lab'] == 'Sin especialidad')&
          (t11['cons_men'] == 1)&
            (t11['MEN_PLATICA_2'] == 1), 'clasif'] = 'Art_Vis'

t11.loc[(t11['SECTOR1_lab'] == 'Otros')&
        (t11['SUBSECTOR1_lab'] == 'Otro Formación General')&
         #(t11['ESP_ID_1_lab'] == 'Sin especialidad')&
          (t11['cons_men'] == 1)&
            (t11['MEN_PLATICA_2'] == 1), 'clasif'] = 'Art_Vis'

################################################################################
#Art_Mus
t11.loc[(t11['SUBSECTOR1_lab'] == 'Artes Musicales') & (t11['clasif'] == 'NA'), 'clasif'] = 'Art_Mus'
t11.loc[(t11['SECTOR1_lab'] == 'Artes')&(t11['ESP_ID_1_lab'] == 'Artes Musicales') & (t11['clasif'] == 'NA'), 'clasif'] = 'Art_Mus'

t11.loc[(t11['SECTOR1_lab'] == 'Artes')&
        (t11['SUBSECTOR1_lab'] == 'Educación Artística')&
         (t11['ESP_ID_1_lab'] == 'Educación Musical')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'Art_Mus'

t11.loc[(t11['SECTOR1_lab'] == 'Artes')&
        (t11['SUBSECTOR1_lab'] == 'Otro')&
         (t11['ESP_ID_1_lab'] == 'Educación Musical')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'Art_Mus'

t11.loc[(t11['SECTOR1_lab'] == 'General')&
        (t11['SUBSECTOR1_lab'] == 'General')&
         (t11['ESP_ID_1_lab'] == 'Educación Musical')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'Art_Mus'

t11.loc[(t11['SECTOR1_lab'] == 'Otros')&
        (t11['SUBSECTOR1_lab'] == 'Otro Formación General')&
         (t11['ESP_ID_1_lab'] == 'Educación Musical')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'Art_Mus'

t11.loc[(t11['SECTOR1_lab'] == 'General')&
        (t11['SUBSECTOR1_lab'] == 'General')&
         #(t11['ESP_ID_1_lab'] == 'Sin especialidad')&
          (t11['cons_men'] == 1)&
            (t11['MEN_ED_MUSICA_1'] == 1), 'clasif'] = 'Art_Mus'

t11.loc[(t11['SECTOR1_lab'] == 'Otros')&
        (t11['SUBSECTOR1_lab'] == 'Otro Formación General')&
         #(t11['ESP_ID_1_lab'] == 'Sin especialidad')&
          (t11['cons_men'] == 1)&
            (t11['MEN_ED_MUSICA_1'] == 1), 'clasif'] = 'Art_Mus'

t11.loc[(t11['SECTOR1_lab'] == 'General')&
        (t11['SUBSECTOR1_lab'] == 'General')&
         #(t11['ESP_ID_1_lab'] == 'Sin especialidad')&
          (t11['cons_men'] == 1)&
            (t11['MEN_ED_MUSICA_2'] == 1), 'clasif'] = 'Art_Mus'

t11.loc[(t11['SECTOR1_lab'] == 'Otros')&
        (t11['SUBSECTOR1_lab'] == 'Otro Formación General')&
         #(t11['ESP_ID_1_lab'] == 'Sin especialidad')&
          (t11['cons_men'] == 1)&
            (t11['MEN_ED_MUSICA_2'] == 1), 'clasif'] = 'Art_Mus'

t11.loc[(t11['SECTOR1_lab'] == 'Artes')&
        (t11['SUBSECTOR1_lab'] == 'Educación Artística')&
         (t11['ESP_ID_1_lab'] == 'Educación Musical'),
          #(t11['cons_men'] == 1)&
           # (t11['MEN_ED_MUSICA_2'] == 1),
            'clasif'] = 'Art_Mus'

t11.loc[(t11['SECTOR1_lab'] == 'Artes')&
        (t11['SUBSECTOR1_lab'] == 'Otro')&
         (t11['ESP_ID_1_lab'] == 'Educación Musical'),
          #(t11['cons_men'] == 1)&
           # (t11['MEN_ED_MUSICA_2'] == 1),
            'clasif'] = 'Art_Mus'

t11.loc[(t11['SECTOR1_lab'] == 'Artes')&
        (t11['SUBSECTOR1_lab'] == 'Educación Artística')&
         (t11['ESP_ID_1_lab'] == 'Artes Musicales'),
          #(t11['cons_men'] == 1)&
           # (t11['MEN_ED_MUSICA_2'] == 1),
            'clasif'] = 'Art_Mus'

t11.loc[(t11['SECTOR1_lab'] == 'Artes')&
        (t11['SUBSECTOR1_lab'] == 'Otro')&
         (t11['ESP_ID_1_lab'] == 'Artes Musicales'),
          #(t11['cons_men'] == 1)&
           # (t11['MEN_ED_MUSICA_2'] == 1),
            'clasif'] = 'Art_Mus'

################################################################################
# Art_esc
t11.loc[(t11['SECTOR1_lab'] == 'Educación Artística')&
        (t11['SUBSECTOR1_lab'] == 'Otro')&
         (t11['ESP_ID_1_lab'] == 'Artes Escénicas')#&
          #(t11['clasif'] == 'NA')
          , 'clasif'] = 'Art_Esc'

t11.loc[(t11['SECTOR1_lab'] == 'Artes')&
        (t11['SUBSECTOR1_lab'] == 'Educación Artística')&
         (t11['ESP_ID_1_lab'] == 'Artes Escénicas')#&
          #(t11['clasif'] == 'NA')
          , 'clasif'] = 'Art_Esc'

t11.loc[(t11['SECTOR1_lab'] == 'Otros')&
        (t11['SUBSECTOR1_lab'] == 'Otro Formación General')&
         (t11['ESP_ID_1_lab'] == 'Artes Escénicas')#&
          #(t11['clasif'] == 'NA')
          , 'clasif'] = 'Art_Esc'

t11.loc[(t11['SECTOR1_lab'] == 'Artes')&
        (t11['SUBSECTOR1_lab'] == 'Otro')&
         (t11['ESP_ID_1_lab'] == 'Artes Escénicas')#&
          #(t11['clasif'] == 'NA')
          , 'clasif'] = 'Art_Esc'

t11.loc[(t11['SECTOR1_lab'] == 'General')&
        (t11['SUBSECTOR1_lab'] == 'General')&
         (t11['ESP_ID_1_lab'] == 'Artes Escénicas')#&
          #(t11['clasif'] == 'NA')
          , 'clasif'] = 'Art_Esc'

t11.loc[(t11['SECTOR1_lab'] == 'Artes')&
        (t11['SUBSECTOR1_lab'] == 'Otro')&
         (t11['ESP_ID_1_lab'] == 'Interpretación en danza de nivel intermedio')#&
          #(t11['clasif'] == 'NA')
          , 'clasif'] = 'Art_Esc'

t11.loc[(t11['SECTOR1_lab'] == 'Artes')&
        (t11['SUBSECTOR1_lab'] == 'Otro')&
         (t11['ESP_ID_1_lab'] == 'Monitoría de danza') #&
          #(t11['clasif'] == 'NA')
          , 'clasif'] = 'Art_Esc'

t11.loc[(t11['SECTOR1_lab'] == 'Artes')&
        (t11['SUBSECTOR1_lab'] == 'Educación Artística')&
         (t11['ESP_ID_1_lab'] == 'Interpretación en danza de nivel intermedio')
         #&(t11['clasif'] == 'NA')
          , 'clasif'] = 'Art_Esc'

t11.loc[(t11['SECTOR1_lab'] == 'Educación Artística')&
        (t11['SUBSECTOR1_lab'] == 'Otro')&
         (t11['ESP_ID_1_lab'] == 'Interpretación en danza de nivel intermedio')#&
         #(t11['clasif'] == 'NA'),
        ,'clasif'] = 'Art_Esc'

#His
t11.loc[(t11['SUBSECTOR1_lab'] == 'Historia y Ciencias Sociales') & (t11['clasif'] == 'NA'), 'clasif'] = 'His'
t11.loc[(t11['SUBSECTOR1_lab'] == 'Estudio y Comprensión de la Sociedad') & (t11['clasif'] == 'NA'), 'clasif'] = 'His'
t11.loc[(t11['SECTOR1_lab'] == 'Ciencia')&(t11['SUBSECTOR1_lab'] == 'Comprensión del Medio Social y Cultural') & (t11['clasif'] == 'NA'), 'clasif'] = 'His'

t11.loc[(t11['SECTOR1_lab'] == 'General')&
        (t11['SUBSECTOR1_lab'] == 'General')&
         (t11['ESP_ID_1_lab'] == 'Ciencias Sociales')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'His'

t11.loc[(t11['SECTOR1_lab'] == 'General')&
        (t11['SUBSECTOR1_lab'] == 'General')&
         (t11['ESP_ID_1_lab'] == 'Historia y Geografía')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'His'


t11.loc[(t11['SECTOR1_lab'] == 'Historia y Ciencias Sociales')&
        (t11['SUBSECTOR1_lab'] == 'Otro')&
         #(t11['ESP_ID_1_lab'] == 'Historia y Geografía')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'His'



t11.loc[(t11['SECTOR1_lab'] == 'Ciencia')&
        (t11['SUBSECTOR1_lab'] == 'Otro')&
         (t11['ESP_ID_1_lab'] == 'Historia y Geografía')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'His'

t11.loc[(t11['SECTOR1_lab'] == 'Otros')&
        (t11['SUBSECTOR1_lab'] == 'Otro Formación General')&
         (t11['ESP_ID_1_lab'] == 'Historia y Geografía')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'His'


t11.loc[(t11['SECTOR1_lab'] == 'General')&
        (t11['SUBSECTOR1_lab'] == 'General')&
         #(t11['ESP_ID_1_lab'] == 'Sin especialidad')&
          (t11['cons_men'] == 1)&
            (t11['MEN_SOCIALES_1'] == 1), 'clasif'] = 'His'

t11.loc[(t11['SECTOR1_lab'] == 'Otros')&
        (t11['SUBSECTOR1_lab'] == 'Otro Formación General')&
         #(t11['ESP_ID_1_lab'] == 'Sin especialidad')&
          (t11['cons_men'] == 1)&
            (t11['MEN_SOCIALES_1'] == 1), 'clasif'] = 'His'

t11.loc[(t11['SECTOR1_lab'] == 'General')&
        (t11['SUBSECTOR1_lab'] == 'General')&
         #(t11['ESP_ID_1_lab'] == 'Sin especialidad')&
          (t11['cons_men'] == 1)&
            (t11['MEN_SOCIALES_2'] == 1), 'clasif'] = 'His'

t11.loc[(t11['SECTOR1_lab'] == 'Otros')&
        (t11['SUBSECTOR1_lab'] == 'Otro Formación General')&
         #(t11['ESP_ID_1_lab'] == 'Sin especialidad')&
          (t11['cons_men'] == 1)&
            (t11['MEN_SOCIALES_2'] == 1), 'clasif'] = 'His'


# filo
t11.loc[(t11['SECTOR1_lab'] == 'Filosofía y Psicología') & (t11['clasif'] == 'NA'), 'clasif'] = 'Ori' # se clasifica en orientación para media


# esp
t11.loc[(t11['SECTOR1_lab'] == 'Educación especial') & (t11['clasif'] == 'NA'), 'clasif'] = 'Esp'

t11.loc[(t11['SECTOR1_lab'] == 'General')&
        (t11['SUBSECTOR1_lab'] == 'General')&
         (t11['ESP_ID_1_lab'] == 'Discapacidad Intelectual')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'Esp'

t11.loc[(t11['SECTOR1_lab'] == 'General')&
        (t11['SUBSECTOR1_lab'] == 'General')&
         (t11['ESP_ID_1_lab'] == 'Trastornos del Aprendizaje')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'Esp'

t11.loc[(t11['SECTOR1_lab'] == 'General')&
        (t11['SUBSECTOR1_lab'] == 'General')&
         (t11['ESP_ID_1_lab'] == 'Trastornos del Lenguaje')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'Esp'

t11.loc[(t11['SECTOR1_lab'] == 'General')&
        (t11['SUBSECTOR1_lab'] == 'Otro Formación General')&
         (t11['ESP_ID_1_lab'] == 'Trastornos de la Audición y Lenguaje')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'Esp'

t11.loc[(t11['SECTOR1_lab'] == 'General')&
        (t11['SUBSECTOR1_lab'] == 'General')&
         (t11['ESP_ID_1_lab'] == 'Trastornos de la Audición y Lenguaje')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'Esp'

t11.loc[(t11['SECTOR1_lab'] == 'Otros')&
        (t11['SUBSECTOR1_lab'] == 'General')&
         (t11['ESP_ID_1_lab'] == 'Discapacidad Intelectual')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'Esp'

t11.loc[(t11['SECTOR1_lab'] == 'Otros')&
        (t11['SUBSECTOR1_lab'] == 'Otro Formación General')&
         (t11['ESP_ID_1_lab'] == 'Discapacidad Intelectual')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'Esp'

t11.loc[(t11['SECTOR1_lab'] == 'Otros')&
        (t11['SUBSECTOR1_lab'] == 'Otro Formación General')&
         (t11['ESP_ID_1_lab'] == 'Trastornos del Aprendizaje')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'Esp'


t11.loc[(t11['SECTOR1_lab'] == 'Otros')&
        (t11['SUBSECTOR1_lab'] == 'Otro Formación General')&
         (t11['ESP_ID_1_lab'] == 'Trastornos del Lenguaje')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'Esp'

# general

t11.loc[(t11['SECTOR1_lab'] == 'General')&
        (t11['SUBSECTOR1_lab'] == 'General')&
         (t11['ESP_ID_1_lab'] == 'Sin especialidad')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'general'

t11.loc[(t11['SECTOR1_lab'] == 'General')&
        (t11['SUBSECTOR1_lab'] == 'General')&
         (t11['ESP_ID_1_lab'] == 'Generalista')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'general'

t11.loc[(t11['SECTOR1_lab'] == 'General')&
        (t11['SUBSECTOR1_lab'] == 'General')&
         (t11['ESP_ID_1_lab'] == 'Otra especialidad')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'general'

t11.loc[(t11['SECTOR1_lab'] == 'Otros')&
        (t11['SUBSECTOR1_lab'] == 'Otro Formación General')&
         (t11['ESP_ID_1_lab'] == 'Otra especialidad')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'general'

t11.loc[(t11['SECTOR1_lab'] == 'General')&
        (t11['SUBSECTOR1_lab'] == 'General')&
         #(t11['ESP_ID_1_lab'] == 'Otra especialidad')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'general'

t11.loc[(t11['SECTOR1_lab'] == 'Otros')&
        (t11['SUBSECTOR1_lab'] == 'Otro Formación General')&
         #(t11['ESP_ID_1_lab'] == 'Otra especialidad')&
          (t11['clasif'] == 'NA'), 'clasif'] = 'general'

df11=t11

# prompt: renombrar clasif por Asig

df11 = df11.rename(columns={'clasif': 'Asig'})

# Verificar si hay columnas duplicadas
print(df11.columns.duplicated())

# prompt: frecuencia 'asig'

#agrupa_cuenta(df11, 'Asig','caso')

#frecuencia_asig = df11['Asig'].value_counts()
#print(frecuencia_asig)

"""rbd_1 - dup_rbd1"""

# duplicados
df11  =df11 .assign(dup_rbd1=df11 [['RBD']].duplicated())
df11 ['dup_rbd1'].value_counts(dropna=False)
# prompt: crear variable  rbd_1 donde la variable es 1 si 'dup_rbd'=false y 0 cuando 'dup_rbd'=


df11['rbd_1'] = np.where(df11['dup_rbd1'] == False, 1, 0)

"""rbd_2"""

# duplicados
df11  =df11 .assign(dup_rbd2=df11 [['RBD','Asig']].duplicated())
df11 ['dup_rbd2'].value_counts(dropna=False)
# prompt: crear variable  rbd_1 donde la variable es 1 si 'dup_rbd'=false y 0 cuando 'dup_rbd'=


df11['rbd_2'] = np.where(df11['dup_rbd2'] == False, 1, 0)

"""rbd_3"""

# duplicados
df11  =df11 .assign(dup_rbd3=df11 [['RBD','Asig','nivel_sector_lab']].duplicated())
df11 ['dup_rbd3'].value_counts(dropna=False)
# prompt: crear variable  rbd_1 donde la variable es 1 si 'dup_rbd'=false y 0 cuando 'dup_rbd'=


df11['rbd_3'] = np.where(df11['dup_rbd3'] == False, 1, 0)

# prompt: reemplazar df11['Asig']="NA" por SC

df11.loc[df11['Asig'] == 'NA', 'Asig'] = 'NA_SC'

# prompt: reemplazar df11['Asig']="NA_SC" por "HLD"

#df11.loc[df11['Asig'] == 'NA_SC', 'Asig'] = 'HLD'

# prompt: eliminar df11 si Asig = "Esp" o Asig="Filo"

df11 = df11[~df11['Asig'].isin(['Esp',
                                #'Filo',
                                ])]

# prompt: agrupa por ens_grado y suma la variable caso

var_aux= ['NIVEL1_lab', 'SECTOR1_lab', 'SUBSECTOR1_lab','ESP_ID_1_lab', 'Asig','cons_men']
var= var_aux + variables_a_convertir # listado de menciones

df_men=agrupa_cuenta_ordenada(df11, var, 'caso')
df_men =df_men.sort_values(by=['caso'], ascending=False)


df_men=agrupa_cuenta_ordenada(df11, var, 'caso')
df_men =df_men.sort_values(by=['caso'], ascending=False)




# exporta a csv y luego importa

df_men.to_csv("/content/drive/MyDrive/analisis_datos/imp_curricular/Insumos/df_men.csv",
               sep=";",
               encoding='iso-8859-1')

dir3='/content/drive/MyDrive/analisis_datos/imp_curricular/Insumos/df_men.csv'

df_men = pd.read_csv(dir3,
                 sep=';',
                 encoding='latin-1',
                 on_bad_lines='skip')


# exportar drive google

#### EXPORTA RBD ####

dfrev=df_men

from google.colab import auth
auth.authenticate_user()

import gspread
from google.auth import default
creds, _ = default()

gc = gspread.authorize(creds)

from gspread_dataframe import set_with_dataframe
sheet = gc.open_by_key("1pOUtbMJBXn6poNcxbBRCAYdQw2KYkVSIcAcwef_SaBY").sheet1
set_with_dataframe(sheet, dfrev)

# prompt: agrupar por [ 'NIVEL1_lab','SECTOR1_lab','SUBSECTOR1_lab','ESP_ID_1','ESP_ID_1_lab','MEN_LENGUAJE_1','Asig', 'caso']sumar caso y sumar 'horas_pl'

# Agrupar por las variables especificadas y sumar 'caso' y 'horas_pl'
g_df11 = df11.groupby(['NIVEL1_lab',
                       'SECTOR1_lab',
                       'SUBSECTOR1_lab',
                       'ESP_ID_1_lab',
                       'cons_men',
                       'MEN_LENGUAJE_1',
                       'MEN_MATE_1',
                       'MEN_NATURALES_1',
                       'MEN_SOCIALES_1',
                       'MEN_ED_FISICA_1',
                       'MEN_ED_TECNO_1',
                       'MEN_INGLES_1',
                       'MEN_PLATICA_1',
                          'Asig'])[['caso', 'horas_pl']].sum()

g_df11 =g_df11.sort_values(by=['caso'], ascending=False)

g_df11.to_csv("/content/drive/MyDrive/analisis_datos/imp_curricular/Insumos/g_df11.csv",
               sep=";",
               encoding='iso-8859-1')

dir3='/content/drive/MyDrive/analisis_datos/imp_curricular/Insumos/g_df11.csv'

g_df11 = pd.read_csv(dir3,
                 sep=';',
                 encoding='latin-1',
                 on_bad_lines='skip')


# exportar drive google

#### EXPORTA RBD #### t11 control clasificadores

dfrev=g_df11

from google.colab import auth
auth.authenticate_user()

import gspread
from google.auth import default
creds, _ = default()

gc = gspread.authorize(creds)

from gspread_dataframe import set_with_dataframe
sheet = gc.open_by_key("1yCbYWzDkE1_9WtLgw9fzJxx_rP5DPr1rHpCF5s8y-8k").sheet1
set_with_dataframe(sheet, dfrev)

df11 ['dup_rbd'].value_counts(dropna=False)

# prompt: crea la variable  doc=1 en df11

df11['doc_1'] = 1 # sirve para contar docentes

"""# (Prueba) df11 abierto por MRUN Curso

Desagrega la base de cargos docentes por MRUN y curso
"""

# prompt: tomar una muestra aleatoria de 10 caso de dfdoc
campos_a_mostrar = ['MRUN','RBD',
                    'COD_REG_RBD',
                    'COD_COM_RBD',
                    'COD_ENS_1',
                    #'HORAS_AULA',
                    'COD_DEPE_lab',
                    'RURAL_RBD_lab',
                    'nivel_sector_lab',
                    'Asig',
                    'horas_pl2',
                    'caso',
                    #'Niv_Plan_lab',
                    'GRADO.1_1',
                    'GRADO.2_1',
                    'GRADO.3_1',
                    'GRADO.4_1',
                    'GRADO.5_1',
                    'GRADO.6_1',
                    'GRADO.7_1',

                    ]

# Assuming dfdoc is your DataFrame
#sample_df11 = df11.sample(n=10, random_state=1)  # Change random_state for different
sample_df11 = df11[campos_a_mostrar]

sample_df11.head()

"""Calcula la cantidad de grados y las horas por grado"""

# prompt: en sample_dfdoc crear un campo que cuente la cantidad de grados que tiene cada MRUN que no sean 0
# Assuming sample_dfdoc is defined as in your provided code

def count_non_zero_grades(row):
  """Counts the number of non-zero grades in a row."""
  grade_columns = ['GRADO.1_1', 'GRADO.2_1', 'GRADO.3_1', 'GRADO.4_1', 'GRADO.5_1', 'GRADO.6_1', 'GRADO.7_1']
  non_zero_grades = [grade for grade in row[grade_columns] if grade != 0]
  return len(non_zero_grades)

sample_df11['cant_gr'] = sample_df11.apply(count_non_zero_grades, axis=1)
sample_df11['horas_pl2_pro'] =  sample_df11['horas_pl2'] / sample_df11['cant_gr']

sample_df11.head()

# prompt: en sample_dfdoc hacer una fila para cada MRUN y un campo Grado que recoja el valor de los campos  'GRADO.1_1', 'GRADO.2_1', 'GRADO.3_1', 'GRADO.4_1', 'GRADO.5_1', 'GRADO.6_1', 'GRADO.7_1' y poner el valor del campo si es >0

import pandas as pd

new_rows = []
for _, row in sample_df11.iterrows():

  rbd = row['RBD']
  mrun = row['MRUN']
  cod_ens_1 = row['COD_ENS_1']
  cod_depe_lab = row['COD_DEPE_lab']
  rural_rbd_lab = row['RURAL_RBD_lab']
  nivel_sector_lab = row['nivel_sector_lab']
  cod_reg_rbd = row['COD_REG_RBD']
  cod_com_rbd = row['COD_COM_RBD']
  asig = row['Asig']
  horas_pl2 = row['horas_pl2']
  horas_pl2_pro = row['horas_pl2_pro']
  cant_gr=row['cant_gr']
  caso=row['caso']
  for i in range(1, 8):
    grado_column = f'GRADO.{i}_1'
    grado_value = row[grado_column]
    if grado_value > 0:
      new_rows.append({'RBD':rbd,
                       'MRUN': mrun,
                       'COD_ENS_1': cod_ens_1,
                       'COD_DEPE_lab': cod_depe_lab,
                       'RURAL_RBD_lab': rural_rbd_lab,
                       'nivel_sector_lab': nivel_sector_lab,
                       'COD_REG_RBD': cod_reg_rbd,
                       'COD_COM_RBD': cod_com_rbd,
                       'Asig': asig,
                       'horas_pl2': horas_pl2,
                       'horas_pl2_pro': horas_pl2_pro ,
                       'cant_gr':cant_gr,
                       'caso':caso,
                       'Grado': grado_value
                       })

new_df = pd.DataFrame(new_rows)


#new_df

# ENSEÑANZA

# prompt: GENERAR VARIABLE ENSE_GRADO = COD_ENDE +"_"+COD_GRADO

new_df['ENSE_GRADO'] = new_df['COD_ENS_1'].astype(str) + "_" + new_df['Grado'].astype(str)


ENSE_GRADO_dic = {  '110_1' : '1B',  '110_2' : '2B',  '110_3' : '3B',  '110_4' : '4B',  '110_5' : '5B',  '110_6' : '6B',  '110_7' : '7B',  '110_8' : '8B',
                    '211_1' : '1B',  '211_2' : '2B',  '211_3' : '3B',  '211_4' : '4B',  '211_5' : '5B',  '211_6' : '6B',  '211_7' : '7B',  '211_8' : '8B',
                    '212_1' : '1B',  '212_2' : '2B',  '212_3' : '3B',  '212_4' : '4B',  '212_5' : '5B',  '212_6' : '6B',  '212_7' : '7B',  '212_8' : '8B',
                    '213_1' : '1B',  '213_2' : '2B',  '213_3' : '3B',  '213_4' : '4B',  '213_5' : '5B',  '213_6' : '6B',  '213_7' : '7B',  '213_8' : '8B',
                    '215_1' : '1B',  '215_2' : '2B',  '215_3' : '3B',  '215_4' : '4B',  '215_5' : '5B',  '215_6' : '6B',  '215_7' : '7B',  '215_8' : '8B',
                    '216_1' : '1B',  '216_2' : '2B',  '216_3' : '3B',  '216_4' : '4B',  '216_5' : '5B',  '216_6' : '6B',  '216_7' : '7B',  '216_8' : '8B',
                    '217_1' : '1B',  '217_2' : '2B',  '217_3' : '3B',  '217_4' : '4B',  '217_5' : '5B',  '217_6' : '6B',  '217_7' : '7B',  '217_8' : '8B',
                    '218_1' : '1B',  '218_2' : '2B',  '218_3' : '3B',  '218_4' : '4B',  '218_5' : '5B',  '218_6' : '6B',  '218_7' : '7B',  '218_8' : '8B',
                    '310_1' : '1M',  '310_2' : '2M', '310_3' : '3M', '310_4' : '4M',
                    '410_1' : '1M',  '410_2' : '2M', '410_3' : '3M', '410_4' : '4M',
                    '510_1' : '1M',  '510_2' : '2M', '510_3' : '3M', '510_4' : '4M',
                    '610_1' : '1M',  '610_2' : '2M', '610_3' : '3M', '610_4' : '4M',
                    '710_1' : '1M',  '710_2' : '2M', '710_3' : '3M', '710_4' : '4M',
                    '810_1' : '1M',  '810_2' : '2M', '810_3' : '3M', '810_4' : '4M',
                    '910_1' : '1M',  '910_2' : '2M', '910_3' : '3M', '910_4' : '4M',
                    }



new_df['ENSE_GRADO_lab'] = new_df.apply(lambda x:ENSE_GRADO_dic .get(x['ENSE_GRADO'], 'Unknown'), axis=1)

resum_var(new_df, 'ENSE_GRADO_lab', 'caso')

# Niv_Plan
Niv_Plan_dic = {  '1B' : '1B-2B',
                  '2B' : '1B-2B',
                  '3B' : '3B-4B',
                  '4B' : '3B-4B',
                  '5B' : '5B-6B',
                  '6B' : '5B-6B',
                  '7B' : '7B-8B',
                  '8B' : '7B-8B',
                  '1M' : '1M-2M',
                  '2M' : '1M-2M',
                  '3M' : '3M-4M',
                  '4M' : '3M-4M',

                  }

new_df['Niv_Plan_lab'] = new_df.apply(lambda x:Niv_Plan_dic .get(x['ENSE_GRADO_lab'], 'Unknown'), axis=1)

resum_var(new_df, 'Niv_Plan_lab', 'caso')

new_df.info()

# duplicados
new_df  =new_df.assign(dup_dir2=new_df [['MRUN']].duplicated())
new_df['dup_dir2'].value_counts(dropna=False)

# prompt: frecuencia para new_df['RBD'] incluye perdidos

# Assuming 'new_df' is already defined as in your provided code.
# Calculate frequency of 'RBD' including missing values.
rbd_frequency = new_df['RBD'].value_counts(dropna=False)
rbd_frequency

"""# Tabla para cruce con dda


"""

# Crear una tabla con los campos, número de columna y tipo de variable
tabla_info = pd.DataFrame({
    'Campo': df11.columns,
    'Número de Columna': range(1, len(df11.columns) + 1),
    'Tipo de Variable': df11.dtypes
})

# Mostrar la tabla
tabla_info

list_var6= [      #'AGNO',
                  'nivel_sector_lab',
                  'RBD',
                  #'NOM_RBD',
                  #'MRUN',
                  #'COD_RBD
                  'COD_REG_RBD',
                  #'COD_PRO_RBD',
                  'COD_COM_RBD',
                  #'NOM_COM_RBD', #####
                  #'COD_DEPE',
                  'COD_DEPE_lab',
                  #'RURAL_RBD',
                  'RURAL_RBD_lab',
                  #'COD_JOR',
                  #'COD_ENSE',
                  #'COD_ENSE_lab',
                  #'COD_ENSE2',
                  #'COD_ENSE2_lab',
                  #'COD_GRADO',
                  #'ENSE_GRADO',
                  #'ENSE_GRADO_lab',
                  'Niv_Plan_lab', # agrupador cada dos niveles
                  #'LET_CUR',
                  #'COD_TIP_CUR',
                  #'COD_RAMA',
                  #'COD_SEC',
                  #'COD_ESPE',
                  #'COD_DES_CUR',
                  #'TIPO_AULA',
                  #'N_ALU',
                  #'cursos',
                  #'COD_COM_RBD_lab',
                  #'Orden_plan_lab',
                  #'nivel_sector_lab',
                  #'pe_vig',
                  #'dif_Int_Flex',
                  #'dif_Min_Flex',
                  #'dif_Max_Flex',
                   'Asig',

                 ]

# Agrupar por las variables especificadas y calcular las estadísticas

# alternativa
##

df111=new_df # alternativa para tomar los cursos

#df111=df11 ###

df12 = df111.groupby(list_var6) \
    .agg(
        horas_pl2=('horas_pl2', 'sum'),
    horas_pl2_pro=('horas_pl2_pro', 'sum'),
       # rbd_1=('rbd_1', 'sum'), ###
       #  rbd_2=('rbd_2', 'sum'), ###
       #  rbd_3=('rbd_3', 'sum'), ###
       # doc_1=('doc_1', 'sum'), ###
        #s_h_esc_vig=('h_esc_vig', 'sum'),
        #s_h_esc_int=('h_esc_int', 'sum'),
        #s_h_esc_min=('h_esc_min', 'sum'),
        #s_h_esc_max=('h_esc_max', 'sum'),
        #s_jde_base=('jde_base', 'sum'),
       # s_var_jde_min=('var_jde_min', 'sum'),
       # s_var_jde_int=('var_jde_int', 'sum'),
       # s_var_jde_max=('var_jde_max', 'sum'),
       # media_h=('media_h', 'mean')
    ) \
    .reset_index()

#df12['h_doc'] =  df12['horas_pl2'] /df12['doc_1']

#df12['h_doc'] = df12['h_doc'].fillna(0)

df12.to_csv("/content/drive/MyDrive/analisis_datos/imp_curricular/Insumos/of1.csv",
               sep=";",
               encoding='iso-8859-1')

#### EXPORTA RBD ####

#dfrev=df12

#from google.colab import auth
#auth.authenticate_user()

#import gspread
#from google.auth import default
#creds, _ = default()

#gc = gspread.authorize(creds)

#from gspread_dataframe import set_with_dataframe
#sheet = gc.open_by_key('1iYaXotwhrTBflTZmsbakT9D1r7EwgyK5pqTVwoD-FFc').sheet1
#set_with_dataframe(sheet, dfrev)



#df12

df12.head()

# prompt: mostrar df12 si RBD = 1174

# Assuming df12 is already defined as in your provided code.

#rbd_to_show = 1174  #@param {type:"integer"}

# Filter df12 based on the provided RBD value.
#df12_filtered = df12[df12['RBD'] == rbd_to_show]

# Display the filtered DataFrame.
#df12_filtered

"""dup_rbd_4"""

# duplicados
df12 =df12.assign(dup_rbd_4=df12 [['RBD', 'Niv_Plan_lab', 'Asig'	]].duplicated())
df12 ['dup_rbd_4'].value_counts(dropna=False)
# prompt: crear variable  rbd_1 donde la variable es 1 si 'dup_rbd'=false y 0 cuando 'dup_rbd'=

"""Tabla dda1 matrícula para cruce"""

df12.info()

# prompt: abir "/content/drive/MyDrive/analisis_datos/imp_curricular/Insumos/dda1.csv"

dda1 = pd.read_csv("/content/drive/MyDrive/analisis_datos/imp_curricular/Insumos/dda1.csv", sep=";", encoding='iso-8859-1')
dda1.info()

dda1.head()

faltan_horas_df = dda1[dda1['RBD'] ==1323]
faltan_horas_df

# duplicados
dda1 =dda1.assign(dup_rbd_5=dda1 [['RBD',
                                    'Niv_Plan_lab',
                                    'Asig'
                                    ]].duplicated())

dda1 ['dup_rbd_5'].value_counts(dropna=False)
# prompt: crear variable  rbd_1 donde la variable es 1 si 'dup_rbd'=false y 0 cuando 'dup_rbd

dda1['v_dda1'] = 1
dda1 ['v_dda1'].value_counts(dropna=False)

# duplicados
dda1  =dda1 .assign(dup_rbd6=dda1 [['RBD']].duplicated())
dda1 ['dup_rbd6'].value_counts(dropna=False)

#dda1['rbd_11'] = np.where(dda1['dup_rbd3'] == False, 1, 0)

# duplicados
dda1  =dda1 .assign(dup_rbd7=dda1 [['RBD']].duplicated())
dda1 ['dup_rbd7'].value_counts(dropna=False)

"""# Cruce dda1 - df12 = dda1_merged - insumo para modelo"""

# prompt: cruzar dda1 con df12  por las variables RBD y Asig manteniendo los datos de dda1

# MERGE

dda1_merged = pd.merge(dda1 [['RBD',
                                   'Asig',
                                   'nivel_sector_lab',
                                   'Niv_Plan_lab',
                                   's_h_esc_vig',
                                   #'s_h_esc_int',
                                   's_h_esc_min',
                                   's_h_esc_max',
                                  'dfmat9',
                                   ]],

                                  df12[['RBD',
                                      'Asig',
                                      'nivel_sector_lab',
                                      'Niv_Plan_lab',
                                      'horas_pl2_pro' ]],
                                      on=['RBD',
                                          'Asig',
                                          'nivel_sector_lab',
                                          'Niv_Plan_lab'],
                                      how='outer' #'left' ahora estamos conservando todo los casos de ambas bases
                                      )



#left
# 'outer'

# ajustes
dda1_merged['horas_pl2_pro'] = dda1_merged['horas_pl2_pro'].fillna(0)

dda1_merged['dif_h'] =  dda1_merged['horas_pl2_pro'] - dda1_merged['s_h_esc_vig']
dda1_merged['dif_h_min'] =  dda1_merged['horas_pl2_pro'] - (dda1_merged['s_h_esc_vig']+ dda1_merged['s_h_esc_min'])
dda1_merged['dif_h_max'] =  dda1_merged['horas_pl2_pro'] - (dda1_merged['s_h_esc_vig']+ dda1_merged['s_h_esc_max'])


dda1_merged['def_vig'] = np.where(dda1_merged['dif_h'] < 0, dda1_merged['dif_h'], 0)
dda1_merged['def_vig_min'] = np.where(dda1_merged['dif_h_min'] < 0, dda1_merged['dif_h_min'], 0)
dda1_merged['def_vig_max'] = np.where(dda1_merged['dif_h_max'] < 0, dda1_merged['dif_h_max'], 0)

dda1_merged['sup_vig'] =  np.where(dda1_merged['dif_h'] > 0, dda1_merged['dif_h'], 0)
dda1_merged['sup_vig_min'] =  np.where(dda1_merged['dif_h_min'] > 0, dda1_merged['dif_h_min'], 0)
dda1_merged['sup_vig_max'] =  np.where(dda1_merged['dif_h_max'] > 0, dda1_merged['dif_h_max'], 0)




#jornadas

href=25.5


#dda1_merged['hd_def_rbd'] = dda1_merged['def_rbd'] / href

dda1_merged.info()

# duplicados
dda1_merged  =dda1_merged.assign(dup_rbd7=dda1_merged [['RBD']].duplicated())
dda1_merged ['dup_rbd7'].value_counts(dropna=False)

"""Dejas solo los rbd de la demanda"""

dda1_merged.to_csv("/content/drive/MyDrive/analisis_datos/imp_curricular/Insumos/dda1_merged.csv",
               sep=";",
               #decimal=",",
               encoding='iso-8859-1')

dda1_merged.info()

dda1_merged.head()

# prompt: frecuencia dda1_merged( dfmat9 incluye nulos

# Assuming dda1_merged is already defined as in your provided code.

# Calculate the frequency of 'dfmat9' values, including nulls.
frequency_dfmat9 = dda1_merged['dfmat9'].value_counts(dropna=False)

# Print the frequency table.
frequency_dfmat9

"""# Casos a modelar"""

# prompt: de dda1_merged generar un listado aleatorio de 20 rbd, solo mostrar la variable rbd

# Seleccionar N RBD aleatorios de dda1_merged

N=10
rbd_aleatorios = dda1_merged['RBD'].sample(n=N, random_state=1)  # random_state para reproducibilidad

# Mostrar solo la variable RBD
#print(rbd_aleatorios)

dda1_merged_10= dda1_merged[dda1_merged['RBD'].isin(rbd_aleatorios)]

#dda1_merged_10= dda1_merged

# casos a revisar

#dda1_merged_1 = dda1_merged_1[(dda1_merged['RBD'] == 25342) | (dda1_merged['RBD'] == 1930)| (dda1_merged['RBD'] == 8485) ]

"""# Modelo horas educación general"""

### PARA PRUEBAS RÁPIDAS ########################

dda1_merged_1= dda1_merged_10

# prompt: modificar reduction , para que sume h_gen1 a def_vig hasta que h_gen1=0 o def_vig=0, que la iteración primero empiece por el mayor def_vig

# mod1: Crea h_gen1, identifica horas general
dda1_merged_1['h_gen1'] = 0  # Inicializar la columna h_gen1 con 0
for index, row in dda1_merged_1.iterrows():
  if row['Asig'] == 'general':
     #Si Asig es 'general', asignar las horas_pl2 a h_gen1
   dda1_merged_1.loc[index, 'h_gen1'] = row['horas_pl2_pro']
# mod2: modelo de asignación de horas

# Ordenar el DataFrame por def_vig de mayor a menor
dda1_merged_1 = dda1_merged_1.sort_values('def_vig', ascending=False)

for index, row in dda1_merged_1.iterrows():
  if row['Asig'] != 'general' and row['def_vig'] < 0:
    rbd_val = row['RBD']
    #nivel_sector_val = row['nivel_sector_lab']
    Niv_Plan_lab = row['Niv_Plan_lab']

    #general_rows = dda1_merged_1[(dda1_merged_1['RBD'] == rbd_val) & (dda1_merged_1['nivel_sector_lab'] == nivel_sector_val) & (dda1_merged_1['Asig'] == 'general')]

    general_rows = dda1_merged_1[(dda1_merged_1['RBD'] == rbd_val) & (dda1_merged_1['Niv_Plan_lab'] == Niv_Plan_lab) & (dda1_merged_1['Asig'] == 'general')]

    for gen_index, gen_row in general_rows.iterrows():
      while dda1_merged_1.loc[gen_index, 'h_gen1'] > 0 and dda1_merged_1.loc[index, 'def_vig'] < 0:

        reduction = min(dda1_merged_1.loc[gen_index, 'h_gen1'], -dda1_merged_1.loc[index, 'def_vig'])

        dda1_merged_1.loc[gen_index, 'h_gen1'] -= reduction
        dda1_merged_1.loc[index, 'def_vig'] += reduction

"""# Modelo horas excedentes y hld"""

# prompt: Ordenar el DataFrame por sup_vig de mayor a menor. Luego asignar las horas sup_vig de cada asignatura de un determinado RBD al def_vig de hld, desde el mayor sup_vig hasta el menor, hasta que def_vig=0  o sup_vig=0

# Ordenar el DataFrame por sup_vig de mayor a menor
dda1_merged_1 = dda1_merged_1.sort_values('sup_vig', ascending=False)

for index, row in dda1_merged_1.iterrows():
  if row['Asig'] != 'HLD' and row['sup_vig'] > 0:
    rbd_val = row['RBD']
    #nivel_sector_val = row['nivel_sector_lab']
    Niv_Plan_lab = row['Niv_Plan_lab']

   # hld_rows = dda1_merged_1[(dda1_merged_1['RBD'] == rbd_val) & (dda1_merged_1['nivel_sector_lab'] == nivel_sector_val) & (dda1_merged_1['Asig'] == 'HLD')]
    hld_rows = dda1_merged_1[(dda1_merged_1['RBD'] == rbd_val) & (dda1_merged_1['Niv_Plan_lab'] == Niv_Plan_lab) & (dda1_merged_1['Asig'] == 'HLD')]

    for hld_index, hld_row in hld_rows.iterrows():
      while dda1_merged_1.loc[hld_index, 'def_vig'] < 0 and dda1_merged_1.loc[index, 'sup_vig'] > 0:
        reduction = min(-dda1_merged_1.loc[hld_index, 'def_vig'], dda1_merged_1.loc[index, 'sup_vig'])

        dda1_merged_1.loc[hld_index, 'def_vig'] += reduction
        dda1_merged_1.loc[index, 'sup_vig'] -= reduction

"""# Modelo horas excedentes misma asignatura

Parte 1: dentro del mismo nivel (nivel_sector_lab)
"""

# prompt: asignar horas  sup_vig de cada Asig de un determinado RBD nivel_sector_lab, al def_vig de la  misma Asig - RBD- nivel_sector_lab, pero de diferente  'Niv_Plan_lab , hasta que  sup_vig=0 o def_vig=0

# Assuming dda1_merged_1 is already defined as in your provided code.

# Ordenar el DataFrame por sup_vig de mayor a menor
dda1_merged_1 = dda1_merged_1.sort_values('sup_vig', ascending=False)

for index, row in dda1_merged_1.iterrows():
  if row['sup_vig'] > 0:
    rbd_val = row['RBD']
    nivel_sector_val = row['nivel_sector_lab']
    asig_val = row['Asig']
    Niv_Plan_lab_val = row['Niv_Plan_lab']

    # Buscar filas con el mismo RBD, nivel_sector_lab y asignatura, pero diferente Niv_Plan_lab
    same_asig_rows = dda1_merged_1[
        (dda1_merged_1['RBD'] == rbd_val) &
        (dda1_merged_1['nivel_sector_lab'] == nivel_sector_val) &
        (dda1_merged_1['Asig'] == asig_val) &
        (dda1_merged_1['Niv_Plan_lab'] != Niv_Plan_lab_val) &
        (dda1_merged_1['def_vig'] < 0)
    ]

    for same_asig_index, same_asig_row in same_asig_rows.iterrows():
      while dda1_merged_1.loc[index, 'sup_vig'] > 0 and dda1_merged_1.loc[same_asig_index, 'def_vig'] < 0:
        reduction = min(dda1_merged_1.loc[index, 'sup_vig'], -dda1_merged_1.loc[same_asig_index, 'def_vig'])
        dda1_merged_1.loc[index, 'sup_vig'] -= reduction
        dda1_merged_1.loc[same_asig_index, 'def_vig'] += reduction

"""Parte 2: se reparte entre niveles"""

# prompt: asignar horas  sup_vig de cada Asig de un determinado RBD nivel_sector_lab, al def_vig de la  misma Asig - RBD- nivel_sector_lab, pero de diferente  'Niv_Plan_lab , hasta que  sup_vig=0 o def_vig=0

# Assuming dda1_merged_1 is already defined as in your provided code.

# Ordenar el DataFrame por sup_vig de mayor a menor
dda1_merged_1 = dda1_merged_1.sort_values('sup_vig', ascending=False)

for index, row in dda1_merged_1.iterrows():
  if row['sup_vig'] > 0:
    rbd_val = row['RBD']
    nivel_sector_val = row['nivel_sector_lab']
    asig_val = row['Asig']
    Niv_Plan_lab_val = row['Niv_Plan_lab']

    # Buscar filas con el mismo RBD, nivel_sector_lab y asignatura, pero diferente Niv_Plan_lab
    same_asig_rows = dda1_merged_1[
        (dda1_merged_1['RBD'] == rbd_val) &
        (dda1_merged_1['nivel_sector_lab'] != nivel_sector_val) &
        (dda1_merged_1['Asig'] == asig_val) &
        #(dda1_merged_1['Niv_Plan_lab'] != Niv_Plan_lab_val) &
        (dda1_merged_1['def_vig'] < 0)
    ]

    for same_asig_index, same_asig_row in same_asig_rows.iterrows():
      while dda1_merged_1.loc[index, 'sup_vig'] > 0 and dda1_merged_1.loc[same_asig_index, 'def_vig'] < 0:
        reduction = min(dda1_merged_1.loc[index, 'sup_vig'], -dda1_merged_1.loc[same_asig_index, 'def_vig'])
        dda1_merged_1.loc[index, 'sup_vig'] -= reduction
        dda1_merged_1.loc[same_asig_index, 'def_vig'] += reduction

"""# Cálculo brecha simple"""

# prompt: en df2 mostrar tabla con los campos y el número de columna y el tipo de variable

# Crear una tabla con los campos, número de columna y tipo de variable
tabla_info = pd.DataFrame({
    'Campo': dda1_merged_1.columns,
    'Número de Columna': range(1, len(dda1_merged_1.columns) + 1),
    'Tipo de Variable': dda1_merged_1.dtypes
})

# Mostrar la tabla
tabla_info

"""Orden"""

dda1_merged_21= dda1_merged_1.sort_values(by=['nivel_sector_lab', 'Niv_Plan_lab' , 'RBD', 'def_vig'], ascending=[True, True, True, False])

"""dda1_merged_2"""

# duplicados
dda1_merged_2  =dda1_merged_21 .assign(dup_rbd_5=dda1_merged_1 [['RBD']].duplicated())
dda1_merged_2 ['dup_rbd_5'].value_counts(dropna=False)
# prompt: crear variable  rbd_1 donde la variable es 1 si 'dup_rbd'=false y 0 cuando 'dup_rbd'=


dda1_merged_2['rbd_0'] = np.where(dda1_merged_2['dup_rbd_5'] == False, 1, 0)
#dda1_merged_1 ['rbd_1'].value_counts(dropna=False)

# duplicados
dda1_merged_2  =dda1_merged_2 .assign(dup_rbd_1=dda1_merged_1 [['RBD', 'Asig']].duplicated())
dda1_merged_2 ['dup_rbd_1'].value_counts(dropna=False)
# prompt: crear variable  rbd_1 donde la variable es 1 si 'dup_rbd'=false y 0 cuando 'dup_rbd'=


dda1_merged_2['rbd_1'] = np.where(dda1_merged_2['dup_rbd_1'] == False, 1, 0)
#dda1_merged_1 ['rbd_1'].value_counts(dropna=False)

# marcar el primer rbd-asig-nivel para contabilizar

# duplicados
dda1_merged_2  =dda1_merged_2 .assign(dup_rbd_10=dda1_merged_2 [['RBD', 'Asig', 'nivel_sector_lab']].duplicated())
dda1_merged_2 ['dup_rbd_10'].value_counts(dropna=False)
# prompt: crear variable  rbd_1 donde la variable es 1 si 'dup_rbd'=false y 0 cuando 'dup_rbd'=


dda1_merged_2['rbd_as_niv'] = np.where(dda1_merged_2['dup_rbd_10'] == False, 1, 0)
#dda1_merged_1 ['rbd_1'].value_counts(dropna=False)

# marcar el primer rbd-nivel para contabilizar

# duplicados
dda1_merged_2  =dda1_merged_2 .assign(dup_rbd_11=dda1_merged_2 [['RBD', 'nivel_sector_lab']].duplicated())
dda1_merged_2 ['dup_rbd_11'].value_counts(dropna=False)
# prompt: crear variable  rbd_1 donde la variable es 1 si 'dup_rbd'=false y 0 cuando 'dup_rbd'=


dda1_merged_2['rbd_niv'] = np.where(dda1_merged_2['dup_rbd_11'] == False, 1, 0)
#dda1_merged_1 ['rbd_1'].value_counts(dropna=False)

#histograma_resumen_0(dda1_merged_2, 'def_vig', 100)

# prompt: crear la variable aj_def_vig = (def_vig - dif_h (si dif_h<0))

dda1_merged_2['aj_def_vig'] = dda1_merged_2['def_vig']

for index, row in dda1_merged_2.iterrows():
  if row['dif_h'] < 0:
    dda1_merged_2.loc[index, 'aj_def_vig'] = row['def_vig'] - row['dif_h']

# prompt: crear la variable aj_sup_vig = (sup_vig - dif_h (si dif_h>0))

dda1_merged_2['aj_sup_vig'] = dda1_merged_2['sup_vig']

for index, row in dda1_merged_2.iterrows():
  if row['dif_h'] > 0:
    dda1_merged_2.loc[index, 'aj_sup_vig'] = row['sup_vig'] - row['dif_h']

dda1_merged.to_csv("/content/drive/MyDrive/analisis_datos/imp_curricular/salida/dda1_merged_2.csv",
               sep=";",
               decimal=",",
               encoding='iso-8859-1')

#### EXPORTA RBD ####

dfrev= dda1_merged_2

from google.colab import auth
auth.authenticate_user()

import gspread
from google.auth import default
creds, _ = default()

gc = gspread.authorize(creds)

from gspread_dataframe import set_with_dataframe
sheet = gc.open_by_key("1RNSHzmv1dF7WkJGp4h48MfbVXar1pFyUFayQZyJ3QOw").sheet1
set_with_dataframe(sheet, dfrev)

"""salida rbd nivel_sector_lab asig"""

# prompt: agrupar dda1 por Asig sumando 's_h_esc_vig' 'horas_pl' y 'dif_h' hd

dda1_agrupado = dda1_merged_2[['nivel_sector_lab',
                               'RBD',
                               'Niv_Plan_lab',
                               #'COD_DEPE_lab',
                               #'RURAL_RBD_lab',
                               'Asig',
                               's_h_esc_vig',
                               #'s_h_esc_max','rbd_1',
                                'horas_pl2_pro',
                                'dif_h',
                                'def_vig',
                                'sup_vig',
                                'h_gen1',
                                'aj_def_vig',
                                'aj_sup_vig',
                                'rbd_as_niv',
                                'rbd_niv',
                                'rbd_0',
]]

#dda1_agrupado[(dda1_agrupado['RBD'] == 25342)]

# prompt: en dda1_agrupado_2 crea la variable def_rbd = 1 si def_vig<0 y 0 en los demás casos

dda1_agrupado['def_rbd'] = np.where(dda1_agrupado['def_vig'] < 0, 1, 0)
# -3 es el percentil 90 de la distribución de déficit

dda1_agrupado.info()

# cuenta rbd - nivel

# prompt: ordenar dda1_merged por nivel_sector_lab RBD def_vig

dda1_agrupado= dda1_agrupado.sort_values(by=['nivel_sector_lab', 'RBD', 'def_vig'], ascending=[True, True, False])

dda1_agrupado.to_csv("/content/drive/MyDrive/analisis_datos/imp_curricular/salida/dda1_agrupado.csv",
               sep=";",
               decimal=",",
               encoding='iso-8859-1')

# prompt: borrar datos de sheet "1bDKANX89w9Z7dTzVSuB9kQovyKNdsjnaA0TZ1nHPWlc" de google sheet

from google.colab import auth
auth.authenticate_user()
import gspread
from google.auth import default
creds, _ = default()
gc = gspread.authorize(creds)

# Open the Google Sheet by its key
sheet = gc.open_by_key("1bDKANX89w9Z7dTzVSuB9kQovyKNdsjnaA0TZ1nHPWlc")

# Select the worksheet you want to clear
worksheet = sheet.sheet1  # Replace 'Sheet1' with the actual worksheet name if different

# Clear the contents of the worksheet
worksheet.clear()

#### EXPORTA RBD ####

dfrev=dda1_agrupado #[(dda1_agrupado['RBD'] == 25342)]

from google.colab import auth
auth.authenticate_user()

import gspread
from google.auth import default
creds, _ = default()

gc = gspread.authorize(creds)

# BORRAR HOJA
  # Open the Google Sheet by its key
sheet = gc.open_by_key("1bDKANX89w9Z7dTzVSuB9kQovyKNdsjnaA0TZ1nHPWlc")
# Select the worksheet you want to clear
worksheet = sheet.sheet1  # Replace 'Sheet1' with the actual worksheet name if different
# Clear the contents of the worksheet
worksheet.clear()

# ESCRIBIR HOJA
from gspread_dataframe import set_with_dataframe
sheet = gc.open_by_key("1bDKANX89w9Z7dTzVSuB9kQovyKNdsjnaA0TZ1nHPWlc").sheet1
set_with_dataframe(sheet, dfrev)

"""salida rbd asig"""

# prompt: agrupar dda1 por Asig sumando 's_h_esc_vig' 'horas_pl' y 'dif_h' hd

dda1_agrupado_2 = dda1_merged_2.groupby(['RBD','Asig']).agg({
    's_h_esc_vig': 'sum',
    #'s_h_esc_max': 'sum',
    #'rbd_11': 'sum',
    'rbd_1': 'sum',
    #'s_h_esc_min': 'sum',
    'horas_pl2_pro': 'sum',
    'dif_h': 'sum',
    'def_vig': 'sum',
    'sup_vig': 'sum',
    #'h_gen': 'sum',
    'h_gen1': 'sum',
    #'h_gen2': 'sum',
    #'hd_def_rbd': 'sum'
}).reset_index()

#dda1_agrupado[(dda1_agrupado['RBD'] == 25342)]

# prompt: en dda1_agrupado_2 crea la variable def_rbd = 1 si def_vig<0 y 0 en los demás casos

dda1_agrupado_2['def_rbd'] = np.where(dda1_agrupado_2['def_vig'] < 0, 1, 0)

# -3 es el percentil 90 de la distribución de déficit

dda1_agrupado_2.to_csv("/content/drive/MyDrive/analisis_datos/imp_curricular/salida/dda1_agrupado_2.csv",
               sep=";",
               decimal=",",
               encoding='iso-8859-1')

#### EXPORTA RBD ####

dfrev=dda1_agrupado_2 #[(dda1_agrupado['RBD'] == 25342)]

from google.colab import auth
auth.authenticate_user()

import gspread
from google.auth import default
creds, _ = default()

gc = gspread.authorize(creds)

from gspread_dataframe import set_with_dataframe
sheet = gc.open_by_key("1X7P8sbYoseMkmYIxo-Ilhj9RxhvvS_0izezgUGviKAM").sheet1
set_with_dataframe(sheet, dfrev)

