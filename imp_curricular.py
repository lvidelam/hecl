# -*- coding: utf-8 -*-
"""imp_curricular.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1al12Fx4fGJ9U8lgRMIj7BpcxVbawmXWx

# Paquetes e importaciones y funciones
"""

import pandas as pd
import numpy as np
from datetime import datetime
from datetime import timedelta

# prompt: crear esta función # Tabla de frecuencias

def tabla_frecuencias(df, var):
  """
  Esta función calcula y muestra una tabla de frecuencias y porcentajes para una variable dada en un DataFrame.

  Args:
    df: El DataFrame que contiene los datos.
    var: El nombre de la variable para la cual se calcularán las frecuencias.

  Returns:
    Un DataFrame con las frecuencias y porcentajes.
  """
  # Calcula las frecuencias
  frecuencias = df[var].value_counts(dropna=False)

  # Calcula los porcentajes
  total = frecuencias.sum()
  porcentajes = (frecuencias / total) * 100

  # Crea un DataFrame con las frecuencias y porcentajes
  tabla = pd.DataFrame({
      'Frecuencia': frecuencias,
      'Porcentaje': porcentajes
  })

  return print(tabla)

# Función resumen por variable sumando el número de alumnos

def resum_var(bd, var1, var2):
  """
  Esta función calcula y muestra un resumen de la suma de una variable (var2) agrupada por otra variable (var1) en un DataFrame (bd).

  Args:
    bd: El DataFrame que contiene los datos.
    var1: El nombre de la variable para agrupar.
    var2: El nombre de la variable para sumar.

  Returns:
    Un DataFrame con el resumen.
  """
  tabla = bd.groupby(var1)[var2].sum().reset_index()
  total = tabla[var2].sum()
  tabla['Porcentaje'] = (tabla[var2] / total) * 100

  # Agrega una fila con el total
  tabla_total = pd.DataFrame({var1: ['Total'], var2: [total], 'Porcentaje': [100]})
  tabla = pd.concat([tabla, tabla_total], ignore_index=True)

  return print(tabla)

# Ejemplo de uso
#resum_var(dfmat, 'COD_DEPE', 'N_ALU')

# prompt: crear una función con # prompt: HISTOGRAMA dfmat2 'N_ALU' CON COLUMNAS MÁS ANGOSTAS MOSTRAR MEDIA Y MEDIANA Y DESVEST
# import matplotlib.pyplot as plt
# import seaborn as sns
# var= 'N_ALU'
# # Calcula la media, mediana y desviación estándar
# media = dfmat2[var].mean()
# mediana = dfmat2[var].median()
# desvest = dfmat2[var].std()
# # Crea el histograma
# plt.figure(figsize=(10, 6))  # Ajusta el tamaño de la

import matplotlib.pyplot as plt
import seaborn as sns

def histograma_resumen(df, var, bins_adj):
  """
  Esta función crea un histograma para una variable dada en un DataFrame,
  muestra la media, mediana y desviación estándar, y ajusta el ancho de las columnas.

  Args:
    df: El DataFrame que contiene los datos.
    var: El nombre de la variable para la cual se creará el histograma.
  """
  # Calcula la media, mediana y desviación estándar
  media = df[var].mean()
  mediana = df[var].median()
  desvest = df[var].std()

  # Crea el histograma
  plt.figure(figsize=(10, 6))
  sns.histplot(df[var], kde=False, bins=bins_adj)  # Ajusta el número de bins según sea necesario

  # Agrega líneas verticales para la media, mediana y desviación estándar
  plt.axvline(media, color='red', linestyle='dashed', linewidth=2, label=f'Media: {media:.2f}')
  #plt.axvline(mediana, color='green', linestyle='dashed', linewidth=2, label=f'Mediana: {mediana:.2f}')
  plt.axvline(desvest, color='None', linestyle='None', linewidth=2, label=f'Desv. Est.: {desvest:.2f}')

  plt.axvline(np.percentile(df[var], 25), color='orange', linestyle='dotted', linewidth=2, label=f'P25.: {np.percentile(df[var], 25):.2f}')
  plt.axvline(np.percentile(df[var], 50), color='green', linestyle='dotted', linewidth=2, label=f'P50.: {np.percentile(df[var], 50):.2f}')
  plt.axvline(np.percentile(df[var], 75), color='orange', linestyle='dotted', linewidth=2, label=f'P75.: {np.percentile(df[var], 75):.2f}')
  plt.axvline(np.percentile(df[var], 90), color='orange', linestyle='dotted', linewidth=2, label=f'P90.: {np.percentile(df[var], 90):.2f}')
  plt.axvline(np.percentile(df[var], 95), color='orange', linestyle='dotted', linewidth=2, label=f'P95.: {np.percentile(df[var], 95):.2f}')

  #plt.axvline(media + desvest, color='blue', linestyle='dotted', linewidth=2)
  #plt.axvline(media - desvest, color='blue', linestyle='dotted', linewidth=2)

  # Configura el título y etiquetas
  plt.title('Histograma de ' + var)
  plt.xlabel(var)
  plt.ylabel('Frecuencia')
  plt.legend()

  # Muestra el gráfico
  plt.show()

# Ejemplo de uso
# histograma_resumen(dfmat2, 'N_ALU')

from google.colab import drive
drive.mount('/content/drive')



"""# Importar archivos matrícula

Base matrícula
"""

dir1='/content/drive/MyDrive/analisis_datos/imp_curricular/Insumos/20240527_Resumen_Matricula_Preliminar_Curso_2024_20240430.csv'

dir2='/content/20240527_Resumen_Matricula_Preliminar_Curso_2024_20240430.csv'

df = pd.read_csv(dir1,
                 sep=';',
                 encoding='iso-8859-1',
                 on_bad_lines='skip')

dfmat0=df
dfmat0 = dfmat0.rename(columns={'ï»¿AGNO': 'AGNO'})

#dfmat.info()

tabla = tabla_frecuencias(dfmat0, 'ESTADO_ESTAB')

# duplicados
dfmat0  =dfmat0 .assign(dup_dir=dfmat0 [['RBD']].duplicated())

tabla = tabla_frecuencias(dfmat0, 'dup_dir')

# detectar campos donde se da la duplicidad

campos= ['RBD', 'COD_ENSE', 'LET_CUR','COD_GRADO', 'COD_TIP_CUR']

dfmat0  =dfmat0 .assign(dup_dir3=dfmat0 [campos].duplicated())

#######################################################################

tabla = tabla_frecuencias(dfmat0, 'dup_dir3')

# prompt: tabla con COD_DEPE Y SUMA DE N_ALU CON PORCENTAJE Y TOTAL FILA
resum_var(dfmat0, 'COD_DEPE', 'N_ALU')



"""# Importar Planes de estudio

Base Planes de Estudio
"""

# prompt: importar datos google sheets 1h7AyX3fp2a3IUevXJjrmM39wrEucuN_LGz3LAeGyE4I

from google.colab import auth
auth.authenticate_user()
import gspread
from google.auth import default
creds, _ = default()
gc = gspread.authorize(creds)
worksheet = gc.open_by_key('1h7AyX3fp2a3IUevXJjrmM39wrEucuN_LGz3LAeGyE4I').sheet1
rows = worksheet.get_all_values()
dfplanes = pd.DataFrame.from_records(rows)

# prompt: la primera fila de dfplanes es el encabezado del data frame

dfplanes = pd.DataFrame.from_records(rows[1:], columns=rows[0])
dfplanes.info()

dfplanes

# prompt: convert pe_vig,  Int_Flex  to float

dfplanes['pe_vig'] = dfplanes['pe_vig'].astype(float)
dfplanes['Int_Flex'] = dfplanes['Int_Flex'].astype(float)
dfplanes['Min_Flex'] = dfplanes['Min_Flex'].astype(float)
dfplanes['Max_Flex'] = dfplanes['Max_Flex'].astype(float)
dfplanes['dif_Int_Flex'] = dfplanes['dif_Int_Flex'].astype(float)
dfplanes['dif_Min_Flex'] = dfplanes['dif_Min_Flex'].astype(float)
dfplanes['dif_Max_Flex'] = dfplanes['dif_Max_Flex'].astype(float)

dfplanes.info()

"""# Importar base de docentes

Base de Docentes
"""

#dfmat0.info()

df1 = pd.read_csv('/content/drive/MyDrive/analisis_datos/imp_curricular/Insumos/20240723_Docentes_2024_20240630_MRUN.csv',
                 sep=';',
                 encoding='latin-1')

dfdoc0=df1
dfdoc0 = dfdoc0.rename(columns={'ï»¿AGNO': 'AGNO'})

dfdoc0.info()

# duplicados
dfdoc0  =dfdoc0 .assign(dup_dir=dfdoc0 [['MRUN']].duplicated())
dfdoc0 ['dup_dir'].value_counts(dropna=False)

# detectar campos donde se da la duplicidad

campos= ['MRUN', 'RBD']

dfdoc0  =dfdoc0 .assign(dup_dir4=dfdoc0 [campos].duplicated())

#######################################################################

tabla = tabla_frecuencias(dfdoc0, 'dup_dir4')

dfdoc0['caso'] = 1

# prompt: convertir dfdoc['HORAS_AULA'] en string

dfdoc0['HORAS_AULA'] = dfdoc0['HORAS_AULA'].astype(str)
dfdoc0['HORAS_AULA'] = dfdoc0['HORAS_AULA'].fillna(0)
dfdoc0['HORAS_AULA'] = pd.to_numeric(dfdoc0['HORAS_AULA'], errors='coerce')

# prompt: convertir dfdoc0['ESP_ID_1'] en número

dfdoc0['ESP_ID_1'] = pd.to_numeric(dfdoc0['ESP_ID_1'], errors='coerce')
dfdoc0['ESP_ID_1'].info()

dfdoc0.info()

#dfdoc['SECTOR1'].info()
#resum_var(dfdoc, 'SECTOR1', 'caso')

"""# Etiqueta variables matrícula"""

dfmat=dfmat0

#dfmat.info()

"""Base de matrícula"""

# prompt: GENERAR VARIABLE ENSE_GRADO = COD_ENDE +"_"+COD_GRADO

dfmat['ENSE_GRADO'] = dfmat['COD_ENSE'].astype(str) + "_" + dfmat['COD_GRADO'].astype(str)

# ESTADO_ESTAB
ESTADO_ESTAB_dic = {  1 : 'Funcionando',
                      2 : 'En receso',
                      3 : 'Cerrado',
                      4 : 'Autorizado sin matrícula'}

dfmat['ESTADO_ESTAB_lab'] = dfmat.apply(lambda x:ESTADO_ESTAB_dic .get(x['ESTADO_ESTAB'], 'Unknown'), axis=1)


# COD_DEPE
COD_DEPE_dic = {  1 : 'Corporación Municipal',
                  2 : 'Municipal DAEM',
                  3 : 'Particular Subvencionado',
                  4 : 'Particular Pagado (o no subvencionado)',
                  5 : 'Corporación de Administración Delegada (DL 3166)',
                  6 : 'Servicio Local de Educación'}

dfmat['COD_DEPE_lab'] = dfmat.apply(lambda x:COD_DEPE_dic .get(x['COD_DEPE'], 'Unknown'), axis=1)


# COD_ENSE2
COD_ENSE2_dic = {  1 : 'Educación Parvularia.',
                   2 : 'Enseñanza Básica Niños.',
                   3 : 'Educación Básica Adultos.',
                   4 : 'Educación Especial',
                   5 : 'Enseñanza Media Humanístico-Científica Jóvenes.',
                   6 : 'Educación Media Humanístico-Científica Adultos.',
                   7 : 'Enseñanza Media Técnico Profesional y Artística, Jóvenes.',
                   8 : 'Educación Media Técnico Profesional y Artística, Adultos.'}

dfmat['COD_ENSE2_lab'] = dfmat.apply(lambda x:COD_ENSE2_dic .get(x['COD_ENSE2'], 'Unknown'), axis=1)


# RURAL_RBD
RURAL_RBD_dic = {  0 : 'Urbano',  1 : 'Rural',}
dfmat['RURAL_RBD_lab'] = dfmat.apply(lambda x:RURAL_RBD_dic .get(x['RURAL_RBD'], 'Unknown'), axis=1)

# COD_ENSE
COD_ENSE_dic = {   10 : 'Educación Parvularia',
                  110 : 'Enseñanza Básica',
                  160 : 'Educación Básica Común Adultos (Decreto 584/2007)',
                  161 : 'Educación Básica Especial Adultos',
                  163 : 'Escuelas Cárceles (Básica Adultos)',
                  165 : 'Educación Básica Adultos Sin Oficios (Decreto 584/2007)',
                  167 : 'Educación Básica Adultos Con Oficios (Decreto 584/2007 y 999/2009)',
                  211 : 'Educación Especial Discapacidad Auditiva12',
                  212 : 'Educación Especial Discapacidad Intelectual13',
                  213 : 'Educación Especial Discapacidad Visual14',
                  214 : 'Educación Especial Trastornos Específicos del Lenguaje15',
                  215 : 'Educación Especial Trastornos Motores',
                  216 : 'Educación Especial Autismo',
                  217 : 'Educación Especial Discapacidad Graves Alteraciones en la Capacidad de Relación y Comunicación',
                  218 : 'Educación Especial Discapacidad Múltiple',
                  219 : 'Educación Especial Sordoceguera',
                  299 : 'Opción 4 Programa Integración Escolar',
                  310 : 'Enseñanza Media H-C niños y jóvenes',
                  360 : 'Educación Media H-C adultos vespertino y nocturno (Decreto N° 190/1975)',
                  361 : 'Educación Media H-C adultos (Decreto N° 12/1987)',
                  362 : 'Escuelas Cárceles (Media Adultos)',
                  363 : 'Educación Media H-C Adultos (Decreto N°1000/2009)',
                  410 : 'Enseñanza Media T-P Comercial Niños y Jóvenes',
                  460 : 'Educación Media T-P Comercial Adultos (Decreto N° 152/1989)',
                  461 : 'Educación Media T-P Comercial Adultos (Decreto N° 152/1989)',
                  463 : 'Educación Media T-P Comercial Adultos (Decreto N° 1000/2009)',
                  510 : 'Enseñanza Media T-P Industrial Niños y Jóvenes',
                  560 : 'Educación Media T-P Industrial Adultos (Decreto N° 152/1989)',
                  561 : 'Educación Media T-P Industrial Adultos (Decreto N° 152/1989)',
                  563 : 'Educación Media T-P Industrial Adultos (Decreto N° 1000/2009)',
                  610 : 'Enseñanza Media T-P Técnica Niños y Jóvenes',
                  660 : 'Educación Media T-P Técnica Adultos (Decreto N° 152/1989)',
                  661 : 'Educación Media T-P Técnica Adultos (Decreto N° 152/1989)',
                  663 : 'Educación Media T-P Técnica Adultos (Decreto N° 1000/2009)',
                  710 : 'Enseñanza Media T-P Agrícola Niños y Jóvenes',
                  760 : 'Educación Media T-P Agrícola Adultos (Decreto N° 152/1989)',
                  761 : 'Educación Media T-P Agrícola Adultos (Decreto N° 152/1989)',
                  763 : 'Educación Media T-P Agrícola Adultos (Decreto N° 1000/2009)',
                  810 : 'Enseñanza Media T-P Marítima Niños y Jóvenes',
                  860 : 'Enseñanza Media T-P Marítima Adultos (Decreto N° 152/1989)',
                  863 : 'Enseñanza Media T-P Marítima Adultos (Decreto N° 1000/2009)',
                  910 : 'Enseñanza Media Artística Niños y Jóvenes',
                  963 : 'Enseñanza Media Artística Adultos'}

dfmat['COD_ENSE_lab'] = dfmat.apply(lambda x:COD_ENSE_dic .get(x['COD_ENSE'], 'Unknown'), axis=1)

#tabla = tabla_frecuencias(dfmat, 'COD_ENSE_lab')
#print(tabla)

resum_var(dfmat, 'COD_ENSE_lab', 'N_ALU')

#COD_ENSE_dic

# ENSEÑANZA GRADO

ENSE_GRADO_dic = {  '110_1' : '1B',  '110_2' : '2B',  '110_3' : '3B',  '110_4' : '4B',  '110_5' : '5B',  '110_6' : '6B',  '110_7' : '7B',  '110_8' : '8B',
                    '211_1' : '1B',  '211_2' : '2B',  '211_3' : '3B',  '211_4' : '4B',  '211_5' : '5B',  '211_6' : '6B',  '211_7' : '7B',  '211_8' : '8B',
                    '212_1' : '1B',  '212_2' : '2B',  '212_3' : '3B',  '212_4' : '4B',  '212_5' : '5B',  '212_6' : '6B',  '212_7' : '7B',  '212_8' : '8B',
                    '213_1' : '1B',  '213_2' : '2B',  '213_3' : '3B',  '213_4' : '4B',  '213_5' : '5B',  '213_6' : '6B',  '213_7' : '7B',  '213_8' : '8B',
                    '215_1' : '1B',  '215_2' : '2B',  '215_3' : '3B',  '215_4' : '4B',  '215_5' : '5B',  '215_6' : '6B',  '215_7' : '7B',  '215_8' : '8B',
                    '216_1' : '1B',  '216_2' : '2B',  '216_3' : '3B',  '216_4' : '4B',  '216_5' : '5B',  '216_6' : '6B',  '216_7' : '7B',  '216_8' : '8B',
                    '217_1' : '1B',  '217_2' : '2B',  '217_3' : '3B',  '217_4' : '4B',  '217_5' : '5B',  '217_6' : '6B',  '217_7' : '7B',  '217_8' : '8B',
                    '218_1' : '1B',  '218_2' : '2B',  '218_3' : '3B',  '218_4' : '4B',  '218_5' : '5B',  '218_6' : '6B',  '218_7' : '7B',  '218_8' : '8B',
                    '310_1' : '1M',  '310_2' : '2M', '310_3' : '3M', '310_4' : '4M',
                    '410_1' : '1M',  '410_2' : '2M', '410_3' : '3M', '410_4' : '4M',
                    '510_1' : '1M',  '510_2' : '2M', '510_3' : '3M', '510_4' : '4M',
                    '610_1' : '1M',  '610_2' : '2M', '610_3' : '3M', '610_4' : '4M',
                    '710_1' : '1M',  '710_2' : '2M', '710_3' : '3M', '710_4' : '4M',
                    '810_1' : '1M',  '810_2' : '2M', '810_3' : '3M', '810_4' : '4M',
                    '910_1' : '1M',  '910_2' : '2M', '910_3' : '3M', '910_4' : '4M',
                    }



dfmat['ENSE_GRADO_lab'] = dfmat.apply(lambda x:ENSE_GRADO_dic .get(x['ENSE_GRADO'], 'Unknown'), axis=1)

resum_var(dfmat, 'ENSE_GRADO_lab', 'N_ALU')

# Niv_Plan
Niv_Plan_dic = {  '1B' : '1B-2B',
                  '2B' : '1B-2B',
                  '3B' : '3B-4B',
                  '4B' : '3B-4B',
                  '5B' : '5B-6B',
                  '6B' : '5B-6B',
                  '7B' : '7B-8B',
                  '8B' : '7B-8B',
                  '1M' : '1M-2M',
                  '2M' : '1M-2M',
                  '3M' : '3M-4M',
                  '4M' : '3M-4M',

                  }

dfmat['Niv_Plan_lab'] = dfmat.apply(lambda x:Niv_Plan_dic .get(x['ENSE_GRADO_lab'], 'Unknown'), axis=1)

resum_var(dfmat, 'Niv_Plan_lab', 'N_ALU')

# Orden_plan

Orden_plan_dic = {  '1B-2B' : 1,
                    '3B-4B' : 2,
                    '5B-6B' : 3,
                    '7B-8B' : 4,
                    '1M-2M' : 5,
                    '3M-4M' : 6,
                                  }
dfmat['Orden_plan_lab'] = dfmat.apply(lambda x:Orden_plan_dic .get(x['Niv_Plan_lab'], 'Unknown'), axis=1)


resum_var(dfmat, 'Orden_plan_lab', 'N_ALU')

# nivel sector para cruce con horas

# nivel_sector
nivel_sector_dic = {  '1B-2B' : 'Educación General Básica',
                      '3B-4B' : 'Educación General Básica',
                      '5B-6B' : 'Educación General Básica',
                      '7B-8B' : 'Educación General Básica',
                      '1M-2M' : 'Educación Media H-C, T-P y Artística, Formación General ',
                      '3M-4M' : 'Educación Media H-C, T-P y Artística, Formación General ',

                      }

dfmat['nivel_sector_lab'] = dfmat.apply(lambda x:nivel_sector_dic .get(x['Niv_Plan_lab'], 'Unknown'), axis=1)

resum_var(dfmat, 'nivel_sector_lab', 'N_ALU')

# COD_COM_RBD
COD_COM_RBD_dic = {  13120 : 'ÑUÑOA'}
dfmat['COD_COM_RBD_lab'] = dfmat.apply(lambda x:COD_COM_RBD_dic .get(x['COD_COM_RBD'], 'Unknown'), axis=1)

"""# Etiqueta variables cargos docentes

Base de docentes
"""

dfdoc=dfdoc0

#resum_var(dfdoc, 'COD_ENS_1', 'caso')

# COD_ETNIA_DOC
COD_ETNIA_DOC_dic = {  0 : 'No pertenece a ninguna etnia (Valor por defecto)',
                      1 : 'Aymará',
                       2 : 'Atacameño (Likan Antai)',
                       3 : 'Colla',
                       4 : 'Diaguita',
                       5 : 'Quechua',
                       6 : 'Rapa Nui (Pascuense)',
                       7 : 'Mapuche',
                       8 : 'Kawáshkar (Alacalufe)',
                       9 : 'Yagán (Yamana)',
                       10 : 'Otra',
                       11 : 'No registra'}

dfdoc['COD_ETNIA_DOC_lab'] = dfdoc.apply(lambda x:COD_ETNIA_DOC_dic .get(x['COD_ETNIA_DOC'], 'Unknown'), axis=1)

# RURAL_RBD
RURAL_RBD_dic = {  0 : 'Urbano',  1 : 'Rural',}
dfdoc['RURAL_RBD_lab'] = dfdoc.apply(lambda x:RURAL_RBD_dic .get(x['RURAL_RBD'], 'Unknown'), axis=1)

# COD_ENSE
COD_ENS_dic = {  10 : 'Educación Parvularia',
                110 : 'Enseñanza Básica',
                  160 : 'Educación Básica Común Adultos (Decreto 584/2007)',
                  161 : 'Educación Básica Especial Adultos',
                  163 : 'Escuelas Cárceles (Básica Adultos)',
                  165 : 'Educación Básica Adultos Sin Oficios (Decreto 584/2007)',
                  167 : 'Educación Básica Adultos Con Oficios (Decreto 584/2007 y 999/2009)',
                  211 : 'Educación Especial Discapacidad Auditiva12',
                  212 : 'Educación Especial Discapacidad Intelectual13',
                  213 : 'Educación Especial Discapacidad Visual14',
                  214 : 'Educación Especial Trastornos Específicos del Lenguaje15',
                  215 : 'Educación Especial Trastornos Motores',
                  216 : 'Educación Especial Autismo',
                  217 : 'Educación Especial Discapacidad Graves Alteraciones en la Capacidad de Relación y Comunicación',
                  218 : 'Educación Especial Discapacidad Múltiple',
                  219 : 'Educación Especial Sordoceguera',
                  299 : 'Opción 4 Programa Integración Escolar',
                  310 : 'Enseñanza Media H-C niños y jóvenes',
                  360 : 'Educación Media H-C adultos vespertino y nocturno (Decreto N° 190/1975)',
                  361 : 'Educación Media H-C adultos (Decreto N° 12/1987)',
                  362 : 'Escuelas Cárceles (Media Adultos)',
                  363 : 'Educación Media H-C Adultos (Decreto N°1000/2009)',
                  410 : 'Enseñanza Media T-P Comercial Niños y Jóvenes',
                  460 : 'Educación Media T-P Comercial Adultos (Decreto N° 152/1989)',
                  461 : 'Educación Media T-P Comercial Adultos (Decreto N° 152/1989)',
                  463 : 'Educación Media T-P Comercial Adultos (Decreto N° 1000/2009)',
                  510 : 'Enseñanza Media T-P Industrial Niños y Jóvenes',
                  560 : 'Educación Media T-P Industrial Adultos (Decreto N° 152/1989)',
                  561 : 'Educación Media T-P Industrial Adultos (Decreto N° 152/1989)',
                  563 : 'Educación Media T-P Industrial Adultos (Decreto N° 1000/2009)',
                  610 : 'Enseñanza Media T-P Técnica Niños y Jóvenes',
                  660 : 'Educación Media T-P Técnica Adultos (Decreto N° 152/1989)',
                  661 : 'Educación Media T-P Técnica Adultos (Decreto N° 152/1989)',
                  663 : 'Educación Media T-P Técnica Adultos (Decreto N° 1000/2009)',
                  710 : 'Enseñanza Media T-P Agrícola Niños y Jóvenes',
                  760 : 'Educación Media T-P Agrícola Adultos (Decreto N° 152/1989)',
                  761 : 'Educación Media T-P Agrícola Adultos (Decreto N° 152/1989)',
                  763 : 'Educación Media T-P Agrícola Adultos (Decreto N° 1000/2009)',
                  810 : 'Enseñanza Media T-P Marítima Niños y Jóvenes',
                  860 : 'Enseñanza Media T-P Marítima Adultos (Decreto N° 152/1989)',
                  863 : 'Enseñanza Media T-P Marítima Adultos (Decreto N° 1000/2009)',
                  910 : 'Enseñanza Media Artística Niños y Jóvenes',
                  963 : 'Enseñanza Media Artística Adultos',
                  990 : 'Otros tipos de servicio',
                  991 : 'Escuelas de deporte',
                  992 : 'Escuelas de Culturas y Difusión Artística',
                  993 : 'Escuelas Hogares',
                  994 : 'Microcentros de diagnóstico',
                  995 : 'Centros de diagnóstico',
                  995 : 'Otros tipos',

                  }

dfdoc['COD_ENS_lab'] = dfdoc.apply(lambda x:COD_ENS_dic .get(x['COD_ENS_1'], 'Unknown'), axis=1)

resum_var(dfdoc, 'COD_ENS_lab', 'caso')

# SECTOR1

SECTOR1_dic = {  '110' : 'Lenguaje y Comunicación',  '115' : 'Lengua Indígena',
                 '120' : 'Matemática',  '130' : 'Ciencia',  '140' : 'Tecnología',
                 '150' : 'Artes',  '160' : 'Educación Física',  '170' : 'Orientación',
                 '180' : 'Religión',  '190' : 'General',  '310' : 'Lenguaje y Comunicación',
                 '320' : 'Matemática',  '330' : 'Historia y Ciencias Sociales',
                 '340' : 'Filosofía y Psicología',  '350' : 'Ciencias Naturales',
                 '360' : 'Educación Tecnológica',  '370' : 'Educación Artística',
                 '380' : 'Educación Física',  '390' : 'Religión',  '395' : 'Otros',
                 '410' : 'Administración y Comercio',  '510' : 'Construcción',
                 '520' : 'Metalmecánico',  '530' : 'Electricidad',  '540' : 'Minero',
                 '550' : 'Gráfico',  '560' : 'Química',  '570' : 'Confección',
                 '580' : 'Tecnología y Telecomunicaciones',  '610' : 'Alimentación',
                 '620' : 'Programas y Proyectos Sociales',  '630' : 'Hotelería y Turismo',
                 '710' : 'Maderero',  '720' : 'Agropecuario',  '810' : 'Marítimo',  '910' : 'Otro',
                 '0' : 'No hace clases',  '10' : 'Educación parvularia',  '200' : 'Educación especial',
                 '-3' : 'Educación Básica de adultos',  '165' : 'Educación Básica de adultos sin oficios',
                 '167' : 'Educación Básica de adultos con oficios',  '990' : 'Otro tipo de enseñanza, no formal'}

dfdoc['SECTOR1_lab'] = dfdoc.apply(lambda x:SECTOR1_dic .get(x['SECTOR1'], 'Unknown'), axis=1)

resum_var(dfdoc, 'SECTOR1_lab', 'caso')

# SUBSECTOR1

# SUBSECTOR1
SUBSECTOR1_dic = {  '11001' : 'Lenguaje y Comunicación',  '11002' : 'Idioma Extranjero Inglés',
                    '11003' : 'Idioma Extranjero (otro)',  '11004' : 'Otro',
                    '11501' : 'Aymará',  '11502' : 'Mapuzugun',  '11503' : 'Quechua',
                    '11504' : 'Rapa Nui',  '11505' : 'Likanantai (Atacameño)',
                    '11506' : 'Colla',  '11507' : 'Diaguita',  '11508' : 'Kawésqar',
                    '11509' : 'Yagán',  '11510' : 'Otro',  '12001' : 'Educación Matemática',
                    '12002' : 'Otro',  '13001' : 'Comprensión del Medio Social y Cultural',
                    '13002' : 'Estudio y Comprensión de la Naturaleza',
                    '13003' : 'Estudio y Comprensión de la Sociedad',  '13004' : 'Otro',
                    '14001' : 'Educación Tecnológica',  '14002' : 'Otro',  '15001' : 'Educación Artística',
                    '15002' : 'Otro',  '16001' : 'Educación Física',  '17001' : 'Orientación',  '18001' : 'Religión',
                    '19001' : 'General',  '31001' : 'Lenguaje y Comunicación',  '31002' : 'Idioma Extranjero Inglés',
                    '31003' : 'Idioma Extranjero (otro)',  '31004' : 'Otro',  '32001' : 'Educación Matemática',
                    '32002' : 'Otro',  '33001' : 'Historia y Ciencias Sociales',  '33002' : 'Otro',
                    '34001' : 'Filosofía y Psicología',  '34002' : 'Otro',  '35001' : 'Biología',  '35002' : 'Química',
                    '35003' : 'Física',  '35004' : 'Otro',  '36001' : 'Educación Tecnológica',  '36002' : 'Otro',
                    '37001' : 'Artes Visuales',  '37002' : 'Artes Musicales',  '37003' : 'Otro',  '38001' : 'Educación Física',
                    '39001' : 'Religión',  '39501' : 'Otro Formación General',  '41001' : 'Administración',
                    '41002' : 'Contabilidad',  '41003' : 'Secretariado',  '41004' : 'Ventas',  '51001' : 'Edificación',
                    '51002' : 'Terminaciones de Construcción',  '51003' : 'Montaje Industrial',  '51004' : 'Obras Viales y de Infraestructura',
                    '51005' : 'Instalaciones sanitarias',  '51006' : 'Refrigeración y climatización',  '52008' : 'Mecánica industrial',
                    '52009' : 'Construcciones metálicas',  '52010' : 'Mecánica',  '52011' : 'Matricería',  '52012' : 'Mecánica de mantención de aeronaves',
                    '53014' : 'Electricidad',  '53015' : 'Electrónica',  '53016' : 'Telecomunicaciones52',  '54018' : 'Explotación minera',
                    '54019' : 'Metalurgia extractiva',  '54020' : 'Asistencia en geología',  '55022' : 'Gráfica',  '55023' : 'Dibujo técnico',
                    '56025' : 'Operación de planta química',  '56026' : 'Laboratorio químico',  '57028' : 'Tejido',
                    '57029' : 'Textil',  '57030' : 'Vestuario y confección textil',  '57031' : 'Productos del cuero',
                    '58033' : 'Conectividad y Redes',  '58034' : 'Programación',  '58035' : 'Telecomunicaciones',
                    '61001' : 'Elaboración industrial de alimentos',  '61002' : 'Servicio de alimentación colectiva',
                    '62004' : 'Atención de párvulos',  '62005' : 'Atención de adultos mayores',  '62006' : 'Atención de enfermos',
                    '62007' : 'Atención social y recreativa',  '63009' : 'Servicio de Turismo',  '63010' : 'Servicio de Hotelería',
                    '71001' : 'Forestal',  '71002' : 'Procesamiento de la madera',  '71003' : 'Productos de la madera',  '71004' : 'Celulosa y papel',
                    '72006' : 'Agropecuaria',  '81001' : 'Naves mercantes y especiales',  '81002' : 'Pesquería',  '81003' : 'Acuicultura',
                    '81004' : 'Operación portuaria',  '91001' : 'Otro Formación Diferenciada',  '0' : 'No hace clases',  '-1' : 'Educación parvularia',
                    '-2' : 'Educación especial',  '-3' : 'Educación Básica de adultos',  '-3' : 'Educación Básica de adultos',
                    '-4' : 'Educación Básica de adultos con oficios',  '990' : 'Otro tipo de enseñanza, no formal'}

dfdoc['SUBSECTOR1_lab'] = dfdoc.apply(lambda x:SUBSECTOR1_dic .get(x['SUBSECTOR1'], 'Unknown'), axis=1)

resum_var(dfdoc, 'SUBSECTOR1_lab', 'caso')

# nivel_sector
nivel_sector_dic = {  '110' : 'Educación General Básica',
                      '115' : 'Educación General Básica',
                      '120' : 'Educación General Básica',
                      '130' : 'Educación General Básica',
                      '140' : 'Educación General Básica',
                      '150' : 'Educación General Básica',
                      '160' : 'Educación General Básica',
                      '170' : 'Educación General Básica',
                      '180' : 'Educación General Básica',
                      '190' : 'Educación General Básica',
                      '310' : 'Educación Media H-C, T-P y Artística, Formación General ',
                      '320' : 'Educación Media H-C, T-P y Artística, Formación General ',
                      '330' : 'Educación Media H-C, T-P y Artística, Formación General ',
                      '340' : 'Educación Media H-C, T-P y Artística, Formación General ',
                      '350' : 'Educación Media H-C, T-P y Artística, Formación General ',
                      '360' : 'Educación Media H-C, T-P y Artística, Formación General ',
                      '370' : 'Educación Media H-C, T-P y Artística, Formación General ',
                      '380' : 'Educación Media H-C, T-P y Artística, Formación General ',
                      '390' : 'Educación Media H-C, T-P y Artística, Formación General ',
                      '395' : 'Educación Media H-C, T-P y Artística, Formación General ',
                      '410' : 'Educación Media T-P y Artística, Formación Diferenciada',
                      '510' : 'Educación Media T-P y Artística, Formación Diferenciada',
                      '520' : 'Educación Media T-P y Artística, Formación Diferenciada',
                      '530' : 'Educación Media T-P y Artística, Formación Diferenciada',
                      '540' : 'Educación Media T-P y Artística, Formación Diferenciada',
                      '550' : 'Educación Media T-P y Artística, Formación Diferenciada',
                      '560' : 'Educación Media T-P y Artística, Formación Diferenciada',
                      '570' : 'Educación Media T-P y Artística, Formación Diferenciada',
                      '580' : 'Educación Media T-P y Artística, Formación Diferenciada',
                      '610' : 'Educación Media T-P y Artística, Formación Diferenciada',
                      '620' : 'Educación Media T-P y Artística, Formación Diferenciada',
                      '630' : 'Educación Media T-P y Artística, Formación Diferenciada',
                      '710' : 'Educación Media T-P y Artística, Formación Diferenciada',
                      '720' : 'Educación Media T-P y Artística, Formación Diferenciada',
                      '810' : 'Educación Media T-P y Artística, Formación Diferenciada',
                      '910' : 'Educación Media T-P y Artística, Formación Diferenciada',
                        '0' : 'Otros tipos de enseñanza',
                       '10' : 'Otros tipos de enseñanza',
                      '200' : 'Otros tipos de enseñanza',
                       '-3' : 'Otros tipos de enseñanza',
                      '165' : 'Otros tipos de enseñanza',
                      '167' : 'Otros tipos de enseñanza',
                      '990' : 'Otros tipos de enseñanza'}



dfdoc['nivel_sector_lab'] = dfdoc.apply(lambda x:nivel_sector_dic .get(x['SECTOR1'], 'Unknown'), axis=1)

resum_var(dfdoc, 'nivel_sector_lab', 'caso')

# Asig
Asig_dic = {  '11001' : 'LyL',  '11002' : 'Ing',  '11003' : 'Ing',  '11004' : 'LyL',
              '12001' : 'Mat',  '12002' : 'Mat',  '13001' : 'His',  '13002' : 'CN',
              '13003' : 'His',  '13004' : 'CN',  '14001' : 'Tec',  '14002' : 'Tec',
              '15001' : 'Art',  '15002' : 'Art_Vis',  '16001' : 'Ed_Fis',  '17001' : 'Ori',
              '18001' : 'Relig',  '19001' : 'HLD',  '31001' : 'LyL',  '31002' : 'Ing',
              '31003' : 'Ing',  '31004' : 'LyL',  '32001' : 'Mat',  '32002' : 'Mat',
              '33001' : 'His',  '33002' : 'His',  '34001' : 'Ori',  '34002' : 'Ori',
              '35001' : 'CN',  '35002' : 'CN',  '35003' : 'CN',  '35004' : 'CN',  '36001' : 'Tec',
              '36002' : 'Tec',  '37001' : 'Art_Vis',  '37002' : 'Art_Mus',  '37003' : 'Art_Esc',
              '38001' : 'Ed_Fis',  '39001' : 'Relig',  '39501' : 'HLD',  '-2' : 'LyL',}

dfdoc['Asig'] = dfdoc.apply(lambda x:Asig_dic .get(x['SUBSECTOR1'], 'Unknown'), axis=1)

resum_var(dfdoc, 'Asig', 'caso')

# Junta nivel 1 y nivel 2 para filtar

dfdoc['N1_N2'] = dfdoc['NIVEL1'].astype(str) + "_" + dfdoc['NIVEL2'].astype(str)

# COD_DEPE
COD_DEPE_dic = {  1 : 'Corporación Municipal',
                  2 : 'Municipal DAEM',
                  3 : 'Particular Subvencionado',
                  4 : 'Particular Pagado (o no subvencionado)',
                  5 : 'Corporación de Administración Delegada (DL 3166)',
                  6 : 'Servicio Local de Educación'}

dfdoc['COD_DEPE_lab'] = dfdoc.apply(lambda x:COD_DEPE_dic .get(x['COD_DEPE'], 'Unknown'), axis=1)

dfdoc['ESP_ID_1'].info()

# ESP_ID_1
ESP_ID_1_dic = {  110 : 'Sin especialidad',  1101 : 'Inglés',  1614 : 'Religión',  1615 : 'Educación Física',  1616 : 'Otro idioma extranjero',
                  1617 : 'Otra especialidad',  120 : 'Sin especialidad',  121 : 'Discapacidad Visual',  122 : 'Discapacidad Intelectual',  123 : 'Discapacidad Auditiva',
                  124 : 'Trastornos del Lenguaje',  125 : 'Trastornos de la Audición y Lenguaje',  126 : 'Autismo',  127 : 'Trastornos del Aprendizaje',
                  1208 : 'Graves alteraciones en la capacidad de relación y comunicación',  1618 : 'Integración Escolar',  1619 : 'Discapacidades Múltiples',
                  1620 : 'Otra especialidad',  130 : 'Sin especialidad',  131 : 'Educación Física',  132 : 'Educación Musical',  133 : 'Religión',
                  134 : 'Intercultural Bilingüe',  1305 : 'Inglés',  1306 : 'Lenguaje y Comunicación',  1621 : 'Educación de Adultos',  1622 : 'Matemática',
                  1623 : 'Ciencias Sociales',  1624 : 'Ciencias Naturales',  1625 : 'Generalista',  1626 : 'Otra especialidad',  140 : 'Sin especialidad',
                  141 : 'Castellano',  142 : 'Matemática',  143 : 'Física',  144 : 'Química',  145 : 'Biología',  146 : 'Ciencias Naturales',  147 : 'Filosofía',
                  148 : 'Historia y Geografía',  149 : 'Educación Física',  1410 : 'Educación Musical',  1411 : 'Artes Plásticas',  1412 : 'Educación Técnico-Manual',
                  1413 : 'Inglés',  1414 : 'Francés',  1415 : 'Otro idioma extranjero',  1416 : 'Religión',  1418 : 'Educación Tecnológica',
                  1419 : 'Media Técnico-Profesional',  1627 : 'Artes Visuales',  1628 : 'Artes Musicales',  1629 : 'Artes Escénicas',  1630 : 'Computación',
                  1631 : 'Danza',  1632 : 'Teatro',  1633 : 'Fuerzas Armadas',  1634 : 'Alemán',  1635 : 'Otra especialidad',  150 : 'Sin especialidad',
                  151 : 'Educación Musical',  1502 : 'Inglés',  1503 : 'Lenguaje y Comunicación',  1636 : 'Artes Visuales',  1637 : 'Artes Musicales',
                  1638 : 'Artes Escénicas',  1639 : 'Francés',  1640 : 'Alemán',  1641 : 'Otra especialidad',  160 : 'Sin especialidad',  161 : 'Educación Física',
                  162 : 'Educación Musical',  163 : 'Religión',  164 : 'Intercultural Bilingüe',  1605 : 'Lenguaje y Comunicación',  1606 : 'Matemática',
                  1613 : 'Inglés',  1642 : 'Artes Plásticas',  1643 : 'Educación Tecnológica',  1644 : 'Artes Escénicas',  1645 : 'Otra especialidad',  200 : 'No aplica',
                  210 : 'Sin especialidad',  220 : 'Sin especialidad',  230 : 'Sin especialidad',  1646 : 'Forestal',  1647 : 'Procesamiento de la Madera',
                  1648 : 'Productos de la Madera',  1649 : 'Celulosa y Papel',  1650 : 'Agropecuaria',  1651 : 'Elaboración Industrial de Alimentos',
                  1652 : 'Servicios de Alimentación Colectiva',  1653 : 'Edificación',  1654 : 'Terminaciones de Construcción',  1655 : 'Montaje Industrial',
                  1656 : 'Obras Viales y de Infraestructura',  1657 : 'Instalaciones Sanitarias',  1658 : 'Refrigeración y Climatización',  1659 : 'Mecánica Industrial',
                  1660 : 'Construcciones Metálicas',  1661 : 'Mecánica Automotriz',  1662 : 'Matricería',  1663 : 'Mecánica de Mantenimiento de Aeronaves',
                  1664 : 'Electricidad',  1665 : 'Electrónica',  1666 : 'Telecomunicaciones',  1667 : 'Naves mercantes y especiales',  1668 : 'Pesquería',
                  1669 : 'Acuicultura',  1670 : 'Operación portuaria',  1671 : 'Explotación Minera',  1672 : 'Metalurgia Extractiva',  1673 : 'Asistencia en geología',
                  1674 : 'Gráfica',  1675 : 'Dibujo técnico',  1676 : 'Tejido',  1677 : 'Textil',  1678 : 'Vestuario y confección textil',  1679 : 'Productos del cuero',
                  1680 : 'Administración',  1681 : 'Contabilidad',  1682 : 'Secretariado',  1683 : 'Ventas',  1684 : 'Atención de párvulos',
                  1685 : 'Atención de adultos mayores',  1686 : 'Atención de enfermería',  1687 : 'Atención social y recreativa',  1688 : 'Operación de planta química',
                  1689 : 'Laboratorio químico',  1690 : 'Servicios de turismo',  1691 : 'Servicios hoteleros',  1692 : 'Otra especialidad',  1693 : 'Artes visuales',
                  1694 : 'Artes audiovisuales',  1695 : 'Diseño',  1696 : 'Interpretación teatral',  1697 : 'Diseño escénico',
                  1698 : 'Interpretación en danza de nivel intermedio',  1699 : 'Monitoría de danza',  1700 : 'Interpretación musical',  1701 : 'Composición musical',
                  1702 : 'Apreciación musical',  1703 : 'Otra especialidad',  1704 : 'Mecánica',  1705 : 'Electricidad',  1706 : 'Carpintería',  1707 : 'Encuadernación',
                  1708 : 'Sastrería',  1709 : 'Imprenta',  1710 : 'Tapicería',  1711 : 'Comercio',  1712 : 'Relojería',  1713 : 'Talabartería',  1714 : 'Zapatería',
                  1715 : 'Fundición',  1716 : 'Tallado',  1717 : 'Cartonaje',  1718 : 'Modas y sombreros',  1719 : 'Tejidos',  1720 : 'Lencería y bordados',
                  1721 : 'Lavandería',  1722 : 'Juguetería',  1723 : 'Peluquería',  1724 : 'Economía doméstica',  1725 : 'Costura',  1726 : 'Dibujo',
                  1727 : 'Corsetería y guantes',  1728 : 'Comercio',  1729 : 'Otro plan vocacional',  1730 : 'Artes Decorativas',  300 : 'No aplica',
                  310 : 'No titulado',  320 : 'No titulado',  330 : 'No titulado'}

dfdoc['ESP_ID_1_lab'] = dfdoc.apply(lambda x:ESP_ID_1_dic .get(x['ESP_ID_1'], 'Unknown'), axis=1)

# NIVEL1
NIVEL1_dic = {  0 : 'No hace clases',
                1 : 'Parvularia',
                2 : 'Básica niños y jóvenes',
                6 : 'Básica adultos',
                3 : 'Especial',
                4 : 'Media H-C niños y jóvenes',
                7 : 'Media H-C adultos',
                5 : 'Media Vocacional (T-P y Artística) niños y jóvenes',
                8 : 'Media Vocacional (T-P y Artística) adultos',}

dfdoc['NIVEL1_lab'] = dfdoc.apply(lambda x:NIVEL1_dic .get(x['NIVEL1'], 'Unknown'), axis=1)

# nivel_sector
nivel_sector_dic_dfdoc = { 2 : 'Educación General Básica',
                           4 : 'Educación Media H-C, T-P y Artística, Formación General ',
                           5 : 'Educación Media H-C, T-P y Artística, Formación General ',

                      }

dfdoc['nivel_sector_lab'] = dfdoc.apply(lambda x:nivel_sector_dic_dfdoc .get(x['NIVEL1'], 'Unknown'), axis=1)

# prompt: frecuencia dfdoc['nivel_sector_lab']

frecuencia_nivel_sector = dfdoc['nivel_sector_lab'].value_counts()
print(frecuencia_nivel_sector)

"""Exporta dfdoc a csv"""

dfdoc.to_csv("/content/drive/MyDrive/analisis_datos/imp_curricular/Insumos/dfdoc.csv",
               sep=";",
               encoding='iso-8859-1')

"""Separa cargos docentes por curso para luego exportar"""

# prompt: tomar una muestra aleatoria de 10 caso de dfdoc


campos_a_mostrar = ['MRUN', 'COD_ENS_1', 'HORAS_AULA','GRADO.1_1', 'GRADO.2_1', 'GRADO.3_1', 'GRADO.4_1', 'GRADO.5_1', 'GRADO.6_1', 'GRADO.7_1']

# Assuming dfdoc is your DataFrame
sample_dfdoc = dfdoc.sample(n=10, random_state=1)  # Change random_state for different
sample_dfdoc = sample_dfdoc[campos_a_mostrar]


sample_dfdoc

# prompt: en sample_dfdoc crear un campo que cuente la cantidad de grados que tiene cada MRUN que no sean 0

import pandas as pd
import numpy as np

# Assuming sample_dfdoc is defined as in your provided code

def count_non_zero_grades(row):
  """Counts the number of non-zero grades in a row."""
  grade_columns = ['GRADO.1_1', 'GRADO.2_1', 'GRADO.3_1', 'GRADO.4_1', 'GRADO.5_1', 'GRADO.6_1', 'GRADO.7_1']
  non_zero_grades = [grade for grade in row[grade_columns] if grade != 0]
  return len(non_zero_grades)

sample_dfdoc['Cant_Gr'] = sample_dfdoc.apply(count_non_zero_grades, axis=1)
sample_dfdoc['HORAS_AULA_pro'] =  sample_dfdoc['HORAS_AULA'] / sample_dfdoc['Cant_Gr']

sample_dfdoc

# prompt: en sample_dfdoc hacer una fila para cada MRUN y un campo Grado que recoja el valor de los campos  'GRADO.1_1', 'GRADO.2_1', 'GRADO.3_1', 'GRADO.4_1', 'GRADO.5_1', 'GRADO.6_1', 'GRADO.7_1' y poner el valor del campo si es >0

import pandas as pd

new_rows = []
for _, row in sample_dfdoc.iterrows():
  mrun = row['MRUN']
  cod_ens_1 = row['COD_ENS_1']
  horas_aula = row['HORAS_AULA']
  horas_aula_pro = row['HORAS_AULA_pro']
  cant_gr=row['Cant_Gr']
  for i in range(1, 8):
    grado_column = f'GRADO.{i}_1'
    grado_value = row[grado_column]
    if grado_value > 0:
      new_rows.append({'MRUN': mrun, 'COD_ENS_1': cod_ens_1, 'HORAS_AULA': horas_aula, 'HORAS_AULA_pro': horas_aula_pro , 'Cant_Gr':cant_gr, 'Grado': grado_value})

new_df = pd.DataFrame(new_rows)
new_df



"""# Filtros matricula

Base de matrícula
"""

# prompt: selecciona solo los casos en que ESTADO_ESTAB=1
dfmat1 = dfmat[dfmat['ESTADO_ESTAB'] == 1]
#resum_var(dfmat, 'ESTADO_ESTAB', 'N_ALU')
resum_var(dfmat1, 'ESTADO_ESTAB', 'N_ALU')

#dfmat1 .info()

# Códigos de enseñanza considerados:Enseñanza básica , Media HC, Media TP, Media Artística, Educación especial hasta 1B -2M

dfmat1 = dfmat1[dfmat1['COD_ENSE'].isin([110,
                                      310,
                                      410,
                                      510,
                                      610,
                                      710,
                                      810,
                                      910,
                                      #211,
                                      #212,
                                      #213,
                                      ##214,
                                      #215,
                                      #216,
                                      #217,
                                      #218,
                                      #219
                                      ])]

resum_var(dfmat1, 'COD_ENSE', 'N_ALU')

#  FILTRO VARIABLE ENSE_GRADO = COD_ENDE +"_"+COD_GRADO

# quitar los 3ros y 4tos medios, parvularia

#dfmat1 = dfmat1[~dfmat1['ENSE_GRADO'].isin(['310_3',
                                         #'310_4',
                                         #'410_3',
                                         #'410_4',
                                         #'510_3',
                                         #'510_4',
                                         #'610_3',
                                         #'610_4',
                                         #'710_3',
                                         #'710_4',
                                         #'810_3',
                                         #'810_4',
                                         #'910_3',
                                         #'910_4',
                                            #'211_21',
                                            #'211_22',
                                            #'211_23',
                                            #'211_24',
                                            #'211_25',
                                            #'211_31',
                                            #'211_32',
                                            #'211_33',
                                            #'212_21',
                                            #'212_22',
                                            #'212_23',
                                            #'212_24',
                                            #'212_25',
                                            #'212_31',
                                            #'212_32',
                                            #'212_33',
                                            #'213_21',
                                            #'213_22',
                                            #'213_23',
                                            #'213_24',
                                            #'213_25',
                                            #'213_31',
                                            #'213_32',
                                            #'213_33',
                                            #'213_34',
                                            #'215_21',
                                            #'215_22',
                                            #'215_23',
                                            #'215_24',
                                            #'215_25',
                                            #'215_31',
                                            #'215_32',
                                            #'215_33',
                                            #'215_34',
                                            #'216_21',
                                            #'216_22',
                                            #'216_23',
                                            #'216_24',
                                            #'216_25',
                                            #'216_31',
                                            #'216_32',
                                            #'216_33',
                                            #'216_16',
                                            #'216_17',
                                            #'216_18',
                                            #'217_21',
                                            #'217_22',
                                            #'217_23',
                                            #'217_24',
                                            #'217_25',
                                            #'217_31',
                                            #'217_32',
                                            #'217_33',
                                            #'218_21',
                                            #'218_22',
                                            #'218_23',
                                            #'218_24',
                                            #'218_25',
                                            #'218_31',
                                            #'218_32',
                                            #'218_33',
                                        # ])]

resum_var(dfmat1, 'COD_ENSE', 'N_ALU')

# indice de tipo de curso = curso simple
dfmat1 = dfmat1[dfmat1['COD_TIP_CUR'] == 0]

# Quitar aula hospitalaria
#dfmat1 = dfmat1[dfmat1['TIPO_AULA'].isin([0,1])]

resum_var(dfmat1, 'COD_TIP_CUR', 'N_ALU')

# quitar educación especial

dfmat1 = dfmat1[~dfmat1['COD_ENSE2_lab'].isin(['Educación Especial'
                                        ])]

resum_var(dfmat1, 'COD_ENSE2_lab', 'N_ALU')

# prompt: en dfmat1 excluir COD_DEPE = 4

dfmat1 = dfmat1[dfmat1['COD_DEPE'] != 4]

resum_var(dfmat1, 'COD_DEPE', 'N_ALU')

resum_var(dfmat1, 'RURAL_RBD', 'N_ALU')
resum_var(dfmat1, 'COD_JOR', 'N_ALU')
resum_var(dfmat1, 'COD_TIP_CUR', 'N_ALU')
resum_var(dfmat1, 'COD_RAMA', 'N_ALU')
resum_var(dfmat1, 'COD_SEC', 'N_ALU')
resum_var(dfmat1, 'COD_ESPE', 'N_ALU')
resum_var(dfmat1, 'COD_DES_CUR', 'N_ALU')
resum_var(dfmat1, 'TIPO_AULA', 'N_ALU')
resum_var(dfmat1, 'COD_DES_CUR', 'N_ALU')
resum_var(dfmat1, 'COD_ENSE2_lab', 'N_ALU')

"""# Filtros cargos docentes

Base docentes
"""

dfdoc1=dfdoc

# Establecimientos funcionando
dfdoc1= dfdoc1[dfdoc1['ESTADO_ESTAB'] == 1]

# Excluye los sin información en el título
dfdoc1 = dfdoc1[~dfdoc1['TIT_ID_1'].isin([ 0, # sin información
                                            3, # No titulado
                                         ])]

# Excluye los que no hacen clases
dfdoc1= dfdoc1[dfdoc1['COD_ENS_1'] != 0]

# Considera que la función principal del docente sea 1 = "docente de aula" o secundaria = 1 "docente de aula"
dfdoc1 = dfdoc1[(dfdoc1['ID_IFP'] == 1) | (dfdoc1['ID_IFS'] == 1)]
#dfdoc1= dfdoc1[dfdoc1['ID_IFP'] == 1]

# Excluye los titulados en especialidades. Si hicieran clases como habilitados en Subsector, uno deduce que fue habilitado

dfdoc1 = dfdoc1[~dfdoc1['TIP_TIT_ID_1'].isin([  '26', # Escuela vocacional
                                                '24', # Media TP
                                                '21', # Técnico nivel superior
                                                '20', # No aplica

                                               ])]

# niveles

dfdoc1 = dfdoc1[~dfdoc1['NIVEL1'].isin([0, # no hace clases
                                        1, # parvularia
                                        6, # Básica adultos
                                        7, # Media Adultos
                                        8, # Media Adultos TP
                                        9, # Otros: Escuelas de deporte, Escuelas hogares, Centros de diagnóstico
                                         ])]

# Códigos de enseñanza considerados:Enseñanza básica , Media HC, Media TP, Media Artística, Educación especial hasta 1B -2M

dfdoc1 = dfdoc1[dfdoc1['COD_ENS_1'].isin([110,
                                          310,
                                          410,
                                          510,
                                          610,
                                          710,
                                          810,
                                          910,
                                          #211,
                                          #212,
                                          #213,
                                          #214,
                                          #215,
                                          #216,
                                          #217,
                                          #218,
                                          #219
                                           ])]

# nivel_sector_lab

dfdoc1 = dfdoc1[~dfdoc1['nivel_sector_lab'].isin(['Educación Media T-P y Artística, Formación Diferenciada',
                                         ])]

# SUBSECTOR 1, quita párvulos y lengua indígena

dfdoc1 = dfdoc1[~dfdoc1['SUBSECTOR1'].isin([  '-1',
                                              '11501',
                                              '11502',
                                              '11503',
                                              '11504',
                                              '11505',
                                              '11506',
                                              '11507',
                                              '11508',
                                              '11509',
                                              '11510',
                                         ])]

# quita particular pagado

dfdoc1 = dfdoc1[~dfdoc1['COD_DEPE'].isin([4,
                                         ])]

#Revisión de frecuencias

resum_var(dfdoc1, 'ESTADO_ESTAB', 'caso')
resum_var(dfdoc1, 'COD_DEPE_lab', 'caso')
resum_var(dfdoc1, 'TIT_ID_1', 'caso')
resum_var(dfdoc1, 'TIT_ID_2', 'caso')
resum_var(dfdoc1, 'TIP_TIT_ID_1', 'caso')
resum_var(dfdoc1, 'TIP_TIT_ID_2', 'caso')
resum_var(dfdoc1, 'COD_ENS_1', 'caso')
resum_var(dfdoc1, 'COD_ENS_2', 'caso')
resum_var(dfdoc1, 'ID_IFP', 'caso')
resum_var(dfdoc1, 'ID_IFS', 'caso')
resum_var(dfdoc1, 'NIVEL1', 'caso')
#resum_var(dfdoc1, 'N1_N2', 'caso')
resum_var(dfdoc1, 'COD_ENS_lab', 'caso')
resum_var(dfdoc1, 'TIP_TIT_ID_1', 'caso')
resum_var(dfdoc1, 'SECTOR1_lab', 'caso')

# prompt: mostrar casos en que dfdoc1['COD_ENS_lab']="Enseñanza Básica"  y dfdoc1['nivel_sector_lab']="Enseñanza Media H-C niños y jóvenes"

dfdoc1[['MRUN','COD_ENS_1','COD_ENS_lab','SECTOR1','nivel_sector_lab']][(dfdoc1['COD_ENS_lab'] == "Enseñanza Básica") & (dfdoc1['nivel_sector_lab'] == "Educación Media H-C, T-P y Artística, Formación General ")]

"""# Procesamiento matrícula

Base matrícula
"""

dfmat2=dfmat1

# duplicados
dfmat2  =dfmat2 .assign(dup_dir2=dfmat2 [['RBD']].duplicated())

tabla = tabla_frecuencias(dfmat2, 'dup_dir2')

resum_var(dfmat2, 'COD_TIP_CUR', 'N_ALU')

# duplicados
dfmat2  =dfmat2 .assign(dup_dir=dfmat2 [['RBD']].duplicated())

tabla = tabla_frecuencias(dfmat2, 'dup_dir')
#resum_var(dfmat1, 'dup_dir', 'N_ALU')

# detectar campos donde se da la duplicidad

campos= ['RBD', 'COD_ENSE', 'LET_CUR','COD_GRADO', 'COD_TIP_CUR']
campos2= ['RBD', 'COD_ENSE', 'LET_CUR','COD_GRADO']

dfmat2  =dfmat2 .assign(dup_dir3=dfmat2 [campos].duplicated())
dfmat2  =dfmat2 .assign(dup_dir4=dfmat2 [campos2].duplicated())

#######################################################################

tabla = tabla_frecuencias(dfmat2, 'dup_dir3')
tabla = tabla_frecuencias(dfmat2, 'dup_dir4')

# prompt: genera la variable cursos=1

dfmat2['cursos'] = 1
#resum_var(dfmat2, 'LET_CUR', 'cursos')

list_var= [       'AGNO',
                  'RBD',
                  'COD_REG_RBD',
                  #'COD_PRO_RBD',
                  'COD_COM_RBD',
                  #'NOM_COM_RBD',
                  #'COD_DEPE',
                  'COD_DEPE_lab',
                  #'RURAL_RBD',
                  'RURAL_RBD_lab',
                  #'COD_JOR',
                  #'COD_ENSE',
                  'COD_ENSE_lab',
                  #'COD_ENSE2',
                  'COD_ENSE2_lab',
                  'COD_GRADO',
                  #'ENSE_GRADO',
                  'ENSE_GRADO_lab',
                  'Niv_Plan_lab',
                  #'LET_CUR',
                  #'COD_TIP_CUR',
                  #'COD_RAMA',
                  #'COD_SEC',
                  #'COD_ESPE',
                  #'COD_DES_CUR',
                  #'TIPO_AULA',
                  'N_ALU',
                  'cursos',
                  #'COD_COM_RBD_lab',
                  'Orden_plan_lab',
                  'nivel_sector_lab'

                 ]

# prompt: Seleccionar variables para agrupación

dfmat3 = dfmat2[list_var]


#dfmat3.head()

dfmat3.info()

# duplicados
dfmat3  =dfmat3 .assign(dup_dir3=dfmat3 [['RBD']].duplicated())

tabla = tabla_frecuencias(dfmat3, 'dup_dir3')

dfmat4=dfmat3

# duplicados


dfmat4  =dfmat4 .assign(dup_dir4=dfmat4 [['RBD']].duplicated())
tabla = tabla_frecuencias(dfmat4, 'dup_dir4')

dfmat41 = dfmat4[dfmat4['dup_dir4'] == False]
dfmat41['casos_rbd'] = 1
resum_var(dfmat41, 'COD_DEPE_lab', 'casos_rbd')

resum_var(dfmat4, 'COD_ENSE2_lab', 'N_ALU')



# prompt: transformar a  dataframe resum_var(dfmat4, 'COD_ENSE2_lab', 'N_ALU')

def resum_var(df, variable, valor):
    """
    Generates a frequency table for a given variable in a DataFrame.
    """
    tabla = pd.DataFrame(df.groupby(variable)[valor].sum())
    tabla['porcentaje'] = (tabla[valor] / tabla[valor].sum()) * 100
    tabla = tabla.sort_values(by=valor, ascending=False)
    return tabla

# Assuming dfmat4 is defined in the preceding code
resum_var(dfmat4, 'COD_ENSE2_lab', 'N_ALU')

"""# Cruce matrícula - planes

Cruce dfmat4 con dfplanes
"""

# prompt: cruzar dfmat4 con dfplanes por la variable Niv_Plan_lab

dfmat5 = pd.merge(dfmat4, dfplanes, on='Niv_Plan_lab', how='left')

dfmat5  =dfmat5 .assign(dup_dir5=dfmat5 [['RBD']].duplicated())

tabla = tabla_frecuencias(dfmat5, 'dup_dir5')

# prompt: generar esc_base_vig = cursos * pe_vig

dfmat5['h_esc_vig'] = dfmat5['cursos'] * dfmat5['pe_vig']
#dfmat5['h_esc_int'] = dfmat5['cursos'] * dfmat5['Int_Flex']
#dfmat5['h_esc_min'] = dfmat5['cursos'] * dfmat5['Min_Flex']
#dfmat5['h_esc_max'] = dfmat5['cursos'] * dfmat5['Max_Flex']

dfmat5['h_esc_int'] = dfmat5['cursos'] * dfmat5['dif_Int_Flex']
dfmat5['h_esc_min'] = dfmat5['cursos'] * dfmat5['dif_Min_Flex']
dfmat5['h_esc_max'] = dfmat5['cursos'] * dfmat5['dif_Max_Flex']

dfmat5.info()

# duplicados
dfmat5  =dfmat5 .assign(dup_dir51=dfmat5 [['RBD']].duplicated())

tabla = tabla_frecuencias(dfmat5, 'dup_dir51')

# prompt: eliminar los casos donde Asig=Filo

dfmat5 = dfmat5[dfmat5['Asig'] != 'Filo']

# prompt: frecuencia dfmat5 'Asig'

tabla = tabla_frecuencias(dfmat5, 'Asig')

"""# Procesamiento cargos docentes"""

dfdoc21=dfdoc1

resum_var(dfdoc21, 'ESTADO_ESTAB', 'caso')
resum_var(dfdoc21, 'COD_DEPE_lab', 'caso')
resum_var(dfdoc21, 'nivel_sector_lab', 'caso')

# convertir horas aula cronológicas en horas pedagógicas lectivas

dfdoc21['horas_pl'] = dfdoc21['HORAS_AULA']*60/45*0.65

dfdoc21.info()

histograma_resumen(dfdoc21, 'HORAS_AULA', 50)

histograma_resumen(dfdoc21, 'horas_pl', 50)

"""Tabla asignatura horas aula docentes"""

dfdoc21.info()

# prompt: guardar dfdoc21 como csv en "/content/drive/MyDrive/analisis_datos/imp_curricular/Insumos separador=";"

dfdoc21.to_csv("/content/drive/MyDrive/analisis_datos/imp_curricular/Insumos/dfdoc21.csv",
               sep=";",
               encoding='iso-8859-1')

dfdoc21.info()
dfdoc21.head()

# prompt: agrupar por 'nivel_sector_lab','SECTOR1','SECTOR1_lab','SUBSECTOR1','SUBSECTOR1_lab',  suma 'caso,' media 'HORAS_AULA', MEDIANA  'HORAS_AULA', DESVIACIÓN ESTANDAR 'HORAS AULA', PERCENTIL 25 'HORAS AULA' Y PERCENTIL 75 HORAS AULA

# Agrupar por las variables especificadas y calcular las estadísticas

#group=['nivel_sector_lab','SECTOR1','SECTOR1_lab','SUBSECTOR1','SUBSECTOR1_lab']
#group=['nivel_sector_lab','SUBSECTOR1_lab','Asig']
group=[
       #'COD_REG_RBD',
       'nivel_sector_lab',
       'Asig',
       'RURAL_RBD_lab'
       ]

VAR="horas_pl"


dfdoc2 = dfdoc21.groupby(group) \
    .agg(
        caso=('caso', 'sum'),
        media_h=(VAR, 'mean'),
        mediana_h=(VAR, 'median'),
        desviacion_estandar_h=(VAR, 'std'),
        #percentil_25_h=(VAR, lambda x: np.percentile(x, 25)),
        #percentil_75_h=(VAR, lambda x: np.percentile(x, 75))
    ) \
    .reset_index()
#df_agrupado

histograma_resumen(dfdoc2, 'media_h', 100)

dfdoc2.info()

# analizar variables en googlesheets

df_var=dfdoc2

from google.colab import auth
auth.authenticate_user()

import gspread
from google.auth import default
creds, _ = default()

gc = gspread.authorize(creds)

# BORRAR HOJA
  # Open the Google Sheet by its key
sheet = gc.open_by_key("1K96rH2xMd9fLod8DFnHdszeejJF7h5V7aNpgyy5xvxA")
# Select the worksheet you want to clear
worksheet = sheet.sheet1  # Replace 'Sheet1' with the actual worksheet name if different
# Clear the contents of the worksheet
worksheet.clear()

from gspread_dataframe import set_with_dataframe
sheet = gc.open_by_key("1K96rH2xMd9fLod8DFnHdszeejJF7h5V7aNpgyy5xvxA").sheet1
set_with_dataframe(sheet, df_var)

"""guarda como csv"""

dfdoc2.to_csv("/content/drive/MyDrive/analisis_datos/imp_curricular/Insumos/dfdoc2.csv",
               sep=";",
               #decimal=",",
               encoding='iso-8859-1')

"""agrupa dfdoc2"""

# prompt: agrupar por 'nivel_sector_lab','SECTOR1','SECTOR1_lab','SUBSECTOR1','SUBSECTOR1_lab',  suma 'caso,' media 'HORAS_AULA', MEDIANA  'HORAS_AULA', DESVIACIÓN ESTANDAR 'HORAS AULA', PERCENTIL 25 'HORAS AULA' Y PERCENTIL 75 HORAS AULA

# Agrupar por las variables especificadas y calcular las estadísticas

# group=['nivel_sector_lab','SECTOR1','SECTOR1_lab','SUBSECTOR1','SUBSECTOR1_lab']
# group=['nivel_sector_lab','SUBSECTOR1_lab','Asig']

group=[
        #'COD_REG_RBD',
       'nivel_sector_lab',
       'Asig',
       'RURAL_RBD_lab',
       'COD_DEPE_lab'
       #'SECTOR1_lab',
      #'SUBSECTOR1_lab',
       #'COD_ENS_lab',
       ##'Niv_Plan_lab',
       #'ESP_ID_1_lab',
       #'NIVEL_1_lab',

       ]

VAR="horas_pl"


dfdoc22 = dfdoc21.groupby(group) \
    .agg(
        caso=('caso', 'sum'),
        media_h=(VAR, 'mean'),
        #mediana_h=(VAR, 'median'),
        #desviacion_estandar_h=(VAR, 'std'),
        #percentil_25_h=(VAR, lambda x: np.percentile(x, 25)),
        #percentil_75_h=(VAR, lambda x: np.percentile(x, 75))
    ) \
    .reset_index()
#df_agrupado

#dfdoc22 = dfdoc22.sample(n=500, replace=True)

dfdoc22.to_csv("/content/drive/MyDrive/analisis_datos/imp_curricular/Insumos/dfdoc22.csv",
               sep=";",
               #decimal=",",
               encoding='iso-8859-1')

dfdoc22.info()
#dfdoc22.head()

"""# Cruce matrícula y cargos docentes

Cruce matricula dfmat5 y horas dfdoc2
"""

dfmat6=dfmat5

dfmat6  =dfmat6 .assign(dup_dir6=dfmat6 [['RBD']].duplicated())

tabla = tabla_frecuencias(dfmat6, 'dup_dir51')

# prompt: cruzar dfmat6 con dfdoc2 por las variable 'Asig' y 'nivel_sector_lab'

dfmat7 = pd.merge(dfmat6, dfdoc2, on=['Asig',
                                      'nivel_sector_lab',
                                      #'COD_REG_RBD',
                                      'RURAL_RBD_lab'
                                       ], how='left')

dfmat7['media_h'] = dfmat7['media_h'].fillna(0)

# prompt: genera el objeto art = promedio de media_h si Asig='Art'

art = dfdoc2[dfdoc2['Asig'] == 'Art']['media_h'].mean()
art_vis = dfdoc2[dfdoc2['Asig'] == 'Art_Vis']['media_h'].mean()
art_esc = dfdoc2[dfdoc2['Asig'] == 'Art_Esc']['media_h'].mean()
art_mus = dfdoc2[dfdoc2['Asig'] == 'Art_Mus']['media_h'].mean()

ori= dfdoc2[dfdoc2['Asig'] == 'Ori']['media_h'].mean()
tec= dfdoc2[dfdoc2['Asig'] == 'Tec']['media_h'].mean()
relig= dfdoc2[dfdoc2['Asig'] == 'Relig']['media_h'].mean()
hld = dfdoc2[dfdoc2['Asig'] == 'HLD']['media_h'].mean()

ing = dfdoc2[dfdoc2['Asig'] == 'Ing']['media_h'].mean()
mat = dfdoc2[dfdoc2['Asig'] == 'Mat']['media_h'].mean()
lyl = dfdoc2[dfdoc2['Asig'] == 'LyL']['media_h'].mean()
his = dfdoc2[dfdoc2['Asig'] == 'His']['media_h'].mean()
cn = dfdoc2[dfdoc2['Asig'] == 'CN']['media_h'].mean()
ef= dfdoc2[dfdoc2['Asig'] == 'Ed_Fis']['media_h'].mean()

print(art)
print(art_vis)
print(art_esc)
print(ori)
print(tec)
print(relig)
print(hld)
print(ing)
print(mat)
print(lyl)
print(his)
print(cn)
print(ef)

# prompt: dfmat7['media_h'] = art_vis si dfmat7['Asig'] == 'Art_Vis' y dfmat7['media_h'] == 0

dfmat7.loc[(dfmat7['Asig'] == 'Art_Esc') & (dfmat7['media_h'] == 0), 'media_h'] = art_esc
dfmat7.loc[(dfmat7['Asig'] == 'Art_Vis') & (dfmat7['media_h'] == 0), 'media_h'] = art_vis
dfmat7.loc[(dfmat7['Asig'] == 'Art') & (dfmat7['media_h'] == 0), 'media_h'] = art
dfmat7.loc[(dfmat7['Asig'] == 'Art_Mus') & (dfmat7['media_h'] == 0), 'media_h'] = art_mus

dfmat7.loc[(dfmat7['Asig'] == 'Ori') & (dfmat7['media_h'] == 0), 'media_h'] = ori
dfmat7.loc[(dfmat7['Asig'] == 'Relig') & (dfmat7['media_h'] == 0), 'media_h'] = relig
dfmat7.loc[(dfmat7['Asig'] == 'HLD') & (dfmat7['media_h'] == 0), 'media_h'] = hld
dfmat7.loc[(dfmat7['Asig'] == 'Tec') & (dfmat7['media_h'] == 0), 'media_h'] = tec

dfmat7.loc[(dfmat7['Asig'] == 'Ing') & (dfmat7['media_h'] == 0), 'media_h'] = ing
dfmat7.loc[(dfmat7['Asig'] == 'Mat') & (dfmat7['media_h'] == 0), 'media_h'] = mat
dfmat7.loc[(dfmat7['Asig'] == 'LyL') & (dfmat7['media_h'] == 0), 'media_h'] = lyl
dfmat7.loc[(dfmat7['Asig'] == 'His') & (dfmat7['media_h'] == 0), 'media_h'] = his
dfmat7.loc[(dfmat7['Asig'] == 'CN') & (dfmat7['media_h'] == 0), 'media_h'] = cn
dfmat7.loc[(dfmat7['Asig'] == 'Ed_Fis') & (dfmat7['media_h'] == 0), 'media_h'] = ef

# prompt: crear las variables Prof_base= h_esc_vig/media_h , dif_prof_int = dif_Int_Flex/media_h ,  dif_prof_min= dif_min_Flex/media_h,     dif_prof_max =  dif_Int_Flex/media_h

dfmat7['jde_base'] = dfmat7['h_esc_vig'] / dfmat7['media_h']
dfmat7['var_jde_min'] = dfmat7['h_esc_min'] / dfmat7['media_h']
dfmat7['var_jde_int'] = dfmat7['h_esc_int'] / dfmat7['media_h']
dfmat7['var_jde_max'] = dfmat7['h_esc_max'] / dfmat7['media_h']

dfmat7['media_h'].describe()
tabla = tabla_frecuencias(dfmat7[dfmat7['media_h'] == 0], 'Asig')

# prompt: dfmat7['Prof_base'].describe()

dfmat7['jde_base'].describe()

dfmat7  =dfmat7.assign(dup_dir7=dfmat7 [['RBD']].duplicated())

tabla = tabla_frecuencias(dfmat7, 'dup_dir7')

histograma_resumen(dfmat7, 'media_h', 50) # ojo que esto es por la desagregación por RBD, plan de estudio cada dos curso, comuna, región

#dfmat7[dfmat7['RBD'] == 1]

#dfmat7.info()

"""Agrupa para salida"""

list_var5= [       #'AGNO',
                  #'RBD',
                  'COD_REG_RBD',
                  #'COD_PRO_RBD',
                  #'COD_COM_RBD',
                  #'NOM_COM_RBD',
                  #'COD_DEPE',
                  'COD_DEPE_lab',
                  #'RURAL_RBD',
                  #'RURAL_RBD_lab',
                  #'COD_JOR',
                  #'COD_ENSE',
                  'COD_ENSE_lab',
                  #'COD_ENSE2',
                  #'COD_ENSE2_lab',
                  #'COD_GRADO',
                  #'ENSE_GRADO',
                  #'ENSE_GRADO_lab',
                  'Niv_Plan_lab',
                  #'LET_CUR',
                  #'COD_TIP_CUR',
                  #'COD_RAMA',
                  #'COD_SEC',
                  #'COD_ESPE',
                  #'COD_DES_CUR',
                  #'TIPO_AULA',
                  #'N_ALU',
                  #'cursos',
                  #'COD_COM_RBD_lab',
                  'Orden_plan_lab',
                  'nivel_sector_lab',
                  'pe_vig',
                  'dif_Int_Flex',
                  'dif_Min_Flex',
                  'dif_Max_Flex',
                   'Asig',

                 ]

# Agrupar por las variables especificadas y calcular las estadísticas

dfmat8 = dfmat7.groupby(list_var5) \
    .agg(
        s_cursos=('cursos', 'sum'),
        s_N_ALU=('N_ALU', 'sum'),
        s_h_esc_vig=('h_esc_vig', 'sum'),
        s_h_esc_int=('h_esc_int', 'sum'),
        s_h_esc_min=('h_esc_min', 'sum'),
        s_h_esc_max=('h_esc_max', 'sum'),
        s_jde_base=('jde_base', 'sum'),
        s_var_jde_min=('var_jde_min', 'sum'),
        s_var_jde_int=('var_jde_int', 'sum'),
        s_var_jde_max=('var_jde_max', 'sum'),
        media_h=('media_h', 'mean')
    ) \
    .reset_index()

#dfmat8.head()

dfmat8.info()

dfmat8.to_csv("/content/drive/MyDrive/analisis_datos/imp_curricular/Insumos/dfmat8.csv",
               sep=";",
               encoding='iso-8859-1')

#dfmat8

"""# Herramientas para revisión cargos docentes"""

#Revisión de frecuencias

resum_var(dfdoc1, 'ESTADO_ESTAB', 'caso')
resum_var(dfdoc1, 'TIT_ID_1', 'caso')
resum_var(dfdoc1, 'TIT_ID_2', 'caso')
resum_var(dfdoc1, 'TIP_TIT_ID_1', 'caso')
resum_var(dfdoc1, 'TIP_TIT_ID_2', 'caso')
resum_var(dfdoc1, 'COD_ENS_1', 'caso')
resum_var(dfdoc1, 'COD_ENS_2', 'caso')
resum_var(dfdoc1, 'ID_IFP', 'caso')
resum_var(dfdoc1, 'ID_IFS', 'caso')
resum_var(dfdoc1, 'NIVEL1', 'caso')
#resum_var(dfdoc1, 'N1_N2', 'caso')
resum_var(dfdoc1, 'COD_ENS_1', 'caso')
resum_var(dfdoc1, 'TIP_TIT_ID_1', 'caso')
resum_var(dfdoc1, 'SECTOR1_lab', 'caso')

histograma_resumen(dfdoc1, 'horas_pl', 50)

histograma_resumen(dfdoc1, 'HORAS_AULA', 100)

"""# Exportaciones"""

#### EXPORTA RBD ####

dfrev=dfmat8

# exportar drive google


from google.colab import auth
auth.authenticate_user()

import gspread
from google.auth import default
creds, _ = default()

gc = gspread.authorize(creds)

from gspread_dataframe import set_with_dataframe
sheet = gc.open_by_key("1S-ETR5UA5OJJ4CmtfGghC8TligaGrF56q6rmpI64obs").sheet1

# Reemplaza los valores NaN, Inf y -Inf con una representación de cadena o un valor numérico adecuado (por ejemplo, 0)
dfrev.replace([np.inf, -np.inf], np.nan, inplace=True)
dfrev.fillna('', inplace=True)

set_with_dataframe(sheet, dfrev)

dir3='/content/drive/MyDrive/analisis_datos/imp_curricular/salida/'
dir3

# prompt: # prompt: exportar dfmat5 a csv en dir3 separado por ";"  utf-8

dfmat5.to_csv(dir3+'dfmat8.csv',
              sep=';',
              encoding='utf-8')

"""# Tabla demanda para cruce

proceso tabla dda1
"""

# prompt: frecuencia dfmat['COD_ENSE2_lab']

tabla = tabla_frecuencias(dfmat7, 'COD_ENSE2_lab')
tabla

list_var6= [      #'AGNO',
                  'RBD',
                  #'COD_REG_RBD',
                  #'COD_PRO_RBD',
                  #'COD_COM_RBD',
                  #'NOM_COM_RBD',
                  #'COD_DEPE',
                  'COD_DEPE_lab',
                  #'RURAL_RBD',
                  'RURAL_RBD_lab',
                  #'COD_JOR',
                  #'COD_ENSE',
                  #'COD_ENSE_lab',
                  #'COD_ENSE2',
                  #'COD_ENSE2_lab',
                  #'COD_GRADO',
                  #'ENSE_GRADO',
                  #'ENSE_GRADO_lab',
                  'Niv_Plan_lab',
                  #'LET_CUR',
                  #'COD_TIP_CUR',
                  #'COD_RAMA',
                  #'COD_SEC',
                  #'COD_ESPE',
                  #'COD_DES_CUR',
                  #'TIPO_AULA',
                  #'N_ALU',
                  #'cursos',
                  #'COD_COM_RBD_lab',
                  #'Orden_plan_lab',
                  'nivel_sector_lab',
                  #'pe_vig',
                  #'dif_Int_Flex',
                  #'dif_Min_Flex',
                  #'dif_Max_Flex',
                   'Asig',

                 ]

# Agrupar por las variables especificadas y calcular las estadísticas

dfmat9 = dfmat7.groupby(list_var6) \
    .agg(
        s_cursos=('cursos', 'sum'),
        s_N_ALU=('N_ALU', 'sum'),
        s_h_esc_vig=('h_esc_vig', 'sum'), #valor absoluto plan
        #s_h_esc_int=('h_esc_int', 'sum'),
        s_h_esc_min=('h_esc_min', 'sum'), #valor absoluto plan
        s_h_esc_max=('h_esc_max', 'sum'),  #valor absoluto plan
        #s_jde_base=('jde_base', 'sum'),
       # s_var_jde_min=('var_jde_min', 'sum'),
       # s_var_jde_int=('var_jde_int', 'sum'),
       # s_var_jde_max=('var_jde_max', 'sum'),
       # media_h=('media_h', 'mean')
    ) \
    .reset_index()


dfmat9['dfmat9'] ='dfmat9'

dfmat9.to_csv("/content/drive/MyDrive/analisis_datos/imp_curricular/Insumos/dda1.csv",
               sep=";",
               encoding='iso-8859-1')

dfmat9.head()

#### EXPORTA RBD ####

# exportar drive google


#from google.colab import auth
#auth.authenticate_user()

#import gspread
#from google.auth import default
#creds, _ = default()

#gc = gspread.authorize(creds)

#from gspread_dataframe import set_with_dataframe
#sheet = gc.open_by_key("1LVqmdKi3KirZWuG-FnmJA1SfZOtPRaGRxS-AYam-rxk").sheet1
#set_with_dataframe(sheet, dfmat9)